{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A.1. PRETRAINED WEIGHTS FOR PREDICTION\n",
   "id": "e73ccdcfdf5dd3cf"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-27T08:51:14.669865Z",
     "start_time": "2025-09-27T08:51:14.659209Z"
    }
   },
   "source": [
    "import os, time, math, sys, pathlib, gc\n",
    "from typing import Tuple, List, Dict\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ==== 1) CẤU HÌNH DỮ LIỆU ====\n",
    "VAL_DIR = r\"E:\\Pycharm\\Advanced-Reading-on-Computer-Vision\\Images\\CNN_MultiClass_data\\validation\"\n",
    "# Thư mục val được kỳ vọng có cấu trúc:\n",
    "# val/\n",
    "#   cats/\n",
    "#   dogs/\n",
    "#   pandas/\n",
    "TARGET_CLASSES = [\"cats\", \"dogs\", \"panda\"]\n",
    "CLASS_TO_IDX = {c: i for i, c in enumerate(TARGET_CLASSES)}"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T08:59:12.817659Z",
     "start_time": "2025-09-27T08:51:14.682497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# ==== 2) KHAI BÁO MODEL PRETRAINED (A.1) ====\n",
    "# Theo tài liệu: dùng các model Keras Applications weights='imagenet' (không train) :contentReference[oaicite:3]{index=3}\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as vgg19_pre\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg16_pre\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as res50_pre, decode_predictions as resnet_decode\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as incv3_pre, decode_predictions as inception_decode\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input as xcep_pre, decode_predictions as xception_decode\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input as mnv2_pre, decode_predictions as mobilenet_decode\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input as effb0_pre, decode_predictions as efficientnet_decode\n",
    "\n",
    "# Mỗi model có size đầu vào & hàm decode riêng (Inception/Xception: 299; phần còn lại: 224) :contentReference[oaicite:4]{index=4}\n",
    "MODEL_SPECS = {\n",
    "    \"VGG16\":      {\"builder\": lambda: VGG16(weights=\"imagenet\"),      \"size\": (224, 224), \"pre\": vgg16_pre,  \"decode\": resnet_decode},\n",
    "    \"VGG19\":      {\"builder\": lambda: VGG19(weights=\"imagenet\"),      \"size\": (224, 224), \"pre\": vgg19_pre,  \"decode\": resnet_decode},\n",
    "    \"ResNet50\":   {\"builder\": lambda: ResNet50(weights=\"imagenet\"),   \"size\": (224, 224), \"pre\": res50_pre,  \"decode\": resnet_decode},\n",
    "    \"InceptionV3\":{\"builder\": lambda: InceptionV3(weights=\"imagenet\"),\"size\": (299, 299), \"pre\": incv3_pre,  \"decode\": inception_decode},\n",
    "    \"Xception\":   {\"builder\": lambda: Xception(weights=\"imagenet\"),   \"size\": (299, 299), \"pre\": xcep_pre,   \"decode\": xception_decode},\n",
    "    \"MobileNetV2\":{\"builder\": lambda: MobileNetV2(weights=\"imagenet\"),\"size\": (224, 224), \"pre\": mnv2_pre,   \"decode\": mobilenet_decode},\n",
    "    \"EfficientNetB0\":{\"builder\": lambda: EfficientNetB0(weights=\"imagenet\"),\"size\": (224, 224), \"pre\": effb0_pre, \"decode\": efficientnet_decode},\n",
    "}\n",
    "\n",
    "# ==== 3) ĐỌC DANH SÁCH ẢNH & NHÃN (val) ====\n",
    "def list_images_with_labels(root_dir: str) -> List[Tuple[str, int]]:\n",
    "    items = []\n",
    "    for cls in TARGET_CLASSES:\n",
    "        cls_dir = os.path.join(root_dir, cls)\n",
    "        if not os.path.isdir(cls_dir):\n",
    "            raise FileNotFoundError(f\"Thiếu thư mục lớp: {cls_dir}\")\n",
    "        for fname in os.listdir(cls_dir):\n",
    "            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                items.append((os.path.join(cls_dir, fname), CLASS_TO_IDX[cls]))\n",
    "    if len(items) == 0:\n",
    "        raise RuntimeError(f\"Không thấy ảnh nào trong {root_dir}\")\n",
    "    return items\n",
    "\n",
    "VAL_ITEMS = list_images_with_labels(VAL_DIR)\n",
    "print(f\"[INFO] Tổng ảnh Validation: {len(VAL_ITEMS)} | Lớp: {TARGET_CLASSES}\")\n",
    "\n",
    "# ==== 4) TIỆN ÍCH LOAD & TIỀN XỬ LÝ ẢNH ====\n",
    "def load_image(path: str, target_size: Tuple[int, int]) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"RGB\").resize(target_size, Image.BILINEAR)\n",
    "    arr = np.asarray(img, dtype=np.float32)\n",
    "    return arr\n",
    "\n",
    "# ==== 5) MAP KẾT QUẢ IMAGENET -> {cats, dogs, pandas} ====\n",
    "# A.1 cho ví dụ decode_predictions (class, description, prob) dựa trên weights ImageNet :contentReference[oaicite:5]{index=5}\n",
    "# Ta map theo mô tả nhãn:\n",
    "def map_imagenet_to_3classes(decoded_topk: List[Tuple[str, str, float]]) -> int:\n",
    "    # Ưu tiên \"panda\" rồi \"dog\" rồi \"cat\" trong top-k\n",
    "    for (_, desc, _) in decoded_topk:\n",
    "        d = desc.lower()\n",
    "        if \"panda\" in d:\n",
    "            return CLASS_TO_IDX[\"panda\"]\n",
    "    for (_, desc, _) in decoded_topk:\n",
    "        d = desc.lower()\n",
    "        if \"dog\" in d:\n",
    "            return CLASS_TO_IDX[\"dogs\"]\n",
    "    for (_, desc, _) in decoded_topk:\n",
    "        d = desc.lower()\n",
    "        if \"cat\" in d:\n",
    "            return CLASS_TO_IDX[\"cats\"]\n",
    "    # nếu không rơi vào 3 nhóm trên, coi như sai (trả về -1)\n",
    "    return -1\n",
    "\n",
    "# ==== 6) HÀM ĐÁNH GIÁ 1 MODEL ====\n",
    "def evaluate_model(model_name: str,\n",
    "                   builder, input_size, preprocess_fn, decoder,\n",
    "                   items: List[Tuple[str, int]],\n",
    "                   batch_size: int = 16,\n",
    "                   top_k: int = 3) -> Dict:\n",
    "    # 6.1 load model & đo thời gian\n",
    "    t0 = time.perf_counter()\n",
    "    model = builder()\n",
    "    load_s = time.perf_counter() - t0\n",
    "\n",
    "    # 6.2 suy luận theo batch & đo thời gian/ảnh\n",
    "    N = len(items)\n",
    "    correct = 0\n",
    "    unknown = 0\n",
    "    predict_times = []\n",
    "\n",
    "    # Chuẩn bị batch\n",
    "    def batch_iter(seq, bs):\n",
    "        for i in range(0, len(seq), bs):\n",
    "            yield seq[i:i+bs]\n",
    "\n",
    "    for batch in batch_iter(items, batch_size):\n",
    "        # Load ảnh\n",
    "        imgs = np.stack([load_image(p, input_size) for (p, _) in batch], axis=0)\n",
    "        y_true = np.array([y for (_, y) in batch], dtype=np.int32)\n",
    "\n",
    "        # Tiền xử lý theo model\n",
    "        x = preprocess_fn(imgs.copy())\n",
    "\n",
    "        # Dự đoán & thời gian\n",
    "        t1 = time.perf_counter()\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        t2 = time.perf_counter()\n",
    "        dt = (t2 - t1) / len(batch)  # giây/ảnh\n",
    "        predict_times.extend([dt] * len(batch))\n",
    "\n",
    "        # Decode & map\n",
    "        decoded = decoder(preds, top=top_k)\n",
    "        y_pred_3 = []\n",
    "        for i in range(len(batch)):\n",
    "            mapped = map_imagenet_to_3classes(decoded[i])\n",
    "            y_pred_3.append(mapped)\n",
    "        y_pred_3 = np.array(y_pred_3, dtype=np.int32)\n",
    "\n",
    "        # Đếm đúng/sai\n",
    "        mask_known = (y_pred_3 != -1)\n",
    "        unknown += int(np.sum(~mask_known))\n",
    "        correct += int(np.sum((y_pred_3 == y_true) & mask_known))\n",
    "\n",
    "    acc = correct / N\n",
    "    avg_pred_sec = float(np.mean(predict_times))\n",
    "    images_per_sec = 1.0 / avg_pred_sec if avg_pred_sec > 0 else float(\"nan\")\n",
    "\n",
    "    # Giải phóng\n",
    "    del model\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Load_s\": load_s,\n",
    "        \"Pred_ms_per_img\": avg_pred_sec * 1000.0,\n",
    "        \"Images_per_s\": images_per_sec,\n",
    "        \"Unknown_mapped\": unknown,\n",
    "        \"Total\": N,\n",
    "    }\n",
    "\n",
    "# ==== 7) CHẠY THỬ TẤT CẢ MODEL & IN BẢNG ====\n",
    "RESULTS = []\n",
    "ORDER = [\n",
    "    \"VGG16\", \"VGG19\", \"ResNet50\", \"InceptionV3\", \"Xception\", \"MobileNetV2\", \"EfficientNetB0\"\n",
    "]\n",
    "for name in ORDER:\n",
    "    spec = MODEL_SPECS[name]\n",
    "    print(f\"\\n=== Running {name} ===\")\n",
    "    out = evaluate_model(\n",
    "        model_name=name,\n",
    "        builder=spec[\"builder\"],\n",
    "        input_size=spec[\"size\"],\n",
    "        preprocess_fn=spec[\"pre\"],\n",
    "        decoder=spec[\"decode\"],\n",
    "        items=VAL_ITEMS,\n",
    "        batch_size=16,\n",
    "        top_k=3\n",
    "    )\n",
    "    RESULTS.append(out)\n",
    "    print(out)\n",
    "\n",
    "# Code đã hoàn thành\n"
   ],
   "id": "9ebe632fe07ca16f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tổng ảnh Validation: 3000 | Lớp: ['cats', 'dogs', 'panda']\n",
      "\n",
      "=== Running VGG16 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 142\u001B[0m\n\u001B[0;32m    140\u001B[0m spec \u001B[38;5;241m=\u001B[39m MODEL_SPECS[name]\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m=== Running \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ===\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 142\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspec\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbuilder\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspec\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreprocess_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspec\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpre\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspec\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdecode\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m    \u001B[49m\u001B[43mitems\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mVAL_ITEMS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\n\u001B[0;32m    151\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m RESULTS\u001B[38;5;241m.\u001B[39mappend(out)\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28mprint\u001B[39m(out)\n",
      "Cell \u001B[1;32mIn[25], line 97\u001B[0m, in \u001B[0;36mevaluate_model\u001B[1;34m(model_name, builder, input_size, preprocess_fn, decoder, items, batch_size, top_k)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m# Dự đoán & thời gian\u001B[39;00m\n\u001B[0;32m     96\u001B[0m t1 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m---> 97\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m t2 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m     99\u001B[0m dt \u001B[38;5;241m=\u001B[39m (t2 \u001B[38;5;241m-\u001B[39m t1) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch)  \u001B[38;5;66;03m# giây/ảnh\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\src\\engine\\training.py:2631\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2629\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[0;32m   2630\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_predict_batch_begin(step)\n\u001B[1;32m-> 2631\u001B[0m     tmp_batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2632\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   2633\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:876\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    873\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    874\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    875\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 876\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    880\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    881\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1266\u001B[0m     args,\n\u001B[0;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1268\u001B[0m     executing_eagerly)\n\u001B[0;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    262\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1494\u001B[0m   )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[0;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[0;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[0;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[0;32m     59\u001B[0m   ]\n\u001B[1;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
