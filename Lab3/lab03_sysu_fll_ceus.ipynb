{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 13240444,
     "sourceType": "datasetVersion",
     "datasetId": 8389632
    }
   ],
   "dockerImageVersionId": 31090,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "colab": {
   "provenance": [],
   "name": "lab03_sysu_fll_ceus"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "initial_id",
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        pass\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPUs:\", gpus)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:33:07.376492Z",
     "start_time": "2025-10-03T09:33:03.396443Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:58.771004Z",
     "iopub.execute_input": "2025-10-03T10:01:58.771604Z",
     "iopub.status.idle": "2025-10-03T10:01:58.776514Z",
     "shell.execute_reply.started": "2025-10-03T10:01:58.77158Z",
     "shell.execute_reply": "2025-10-03T10:01:58.775672Z"
    },
    "id": "initial_id",
    "outputId": "38ca1e89-8e6f-483b-fe34-a4fc2bb1938a"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "TF version: 2.18.0\nGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "id": "2a801a8013ef37d7",
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "ROOT_DIR = r\"/kaggle/input/sysu-ceus-fll/SYSU-CEUS-FLL\"\n",
    "\n",
    "CFG = {\n",
    "    \"binary\": True,  # True = g·ªôp HEM+FNH th√†nh HHE (2-class), False = 3-class\n",
    "    \"split_ratio\": (0.7, 0.15, 0.15),\n",
    "    \"frames\": 2,  # Gi·∫£m xu·ªëng 2 frames ƒë·ªÉ ti·∫øt ki·ªám memory t·ªëi ƒëa\n",
    "    \"img_size\": 32,  # Gi·∫£m xu·ªëng 32x32 ƒë·ªÉ tr√°nh kernel crash\n",
    "    \"batch_size\": 2,  # Batch size nh·ªè nh·∫•t ƒë·ªÉ tr√°nh OOM\n",
    "    \"epochs_head\": 1,  # Gi·∫£m xu·ªëng 1 epoch cho head training\n",
    "    \"epochs_ft\": 1,  # Gi·∫£m xu·ªëng 1 epoch cho fine-tuning\n",
    "    \"lr_head\": 5e-3,  # TƒÉng learning rate ƒë·ªÉ h·ªôi t·ª• nhanh h∆°n\n",
    "    \"lr_ft\": 1e-3,  # TƒÉng learning rate cho fine-tuning\n",
    "    \"weight_decay\": 1e-6,  # Gi·∫£m weight decay\n",
    "    \"shuffle_buffer\": 4,  # Gi·∫£m buffer size xu·ªëng t·ªëi thi·ªÉu\n",
    "    \"num_parallel_calls\": 1,  # Ch·ªâ 1 thread ƒë·ªÉ tr√°nh memory spike\n",
    "    \"cache_ds\": False, # T·∫ÆT dataset caching ƒë·ªÉ ti·∫øt ki·ªám RAM\n",
    "}"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:35:24.145548Z",
     "start_time": "2025-10-03T09:35:24.133642Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:58.777865Z",
     "iopub.execute_input": "2025-10-03T10:01:58.778056Z",
     "iopub.status.idle": "2025-10-03T10:01:58.794077Z",
     "shell.execute_reply.started": "2025-10-03T10:01:58.778037Z",
     "shell.execute_reply": "2025-10-03T10:01:58.793402Z"
    },
    "id": "2a801a8013ef37d7"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "72f67596159c386b",
   "cell_type": "code",
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def list_videos(root: str) -> List[Tuple[str, str]]:\n",
    "    rootp = Path(root)\n",
    "    items = []\n",
    "    for cls_dir in sorted([d for d in rootp.iterdir() if d.is_dir()]):\n",
    "        for vid in cls_dir.glob(\"*.avi\"):\n",
    "            items.append((str(vid), cls_dir.name))\n",
    "    return items\n",
    "\n",
    "def make_split(items: List[Tuple[str,str]], ratios=(0.7,0.15,0.15), seed=SEED):\n",
    "    rnd = random.Random(seed)\n",
    "    items = items.copy()\n",
    "    rnd.shuffle(items)\n",
    "    n = len(items)\n",
    "    n_tr = int(n*ratios[0]); n_va = int(n*ratios[1])\n",
    "    return items[:n_tr], items[n_tr:n_tr+n_va], items[n_tr+n_va:]\n",
    "\n",
    "def label_map_from_items(items: List[Tuple[str,str]], binary=False) -> Dict[str,int]:\n",
    "    classes = sorted({c for _,c in items})\n",
    "    if binary:\n",
    "        merged = []\n",
    "        for c in classes:\n",
    "            cu = c.upper()\n",
    "            if cu in [\"HEM\",\"FNH\"]:\n",
    "                merged.append(\"HHE\")\n",
    "            elif cu == \"HCC\":\n",
    "                merged.append(\"HCC\")\n",
    "            else:\n",
    "                merged.append(c)\n",
    "        # ∆Øu ti√™n HCC tr∆∞·ªõc HHE\n",
    "        classes = sorted(set(merged), key=lambda x: 0 if x==\"HCC\" else 1)\n",
    "    return {c:i for i,c in enumerate(classes)}\n",
    "\n",
    "def remap_label(label: str, binary: bool) -> str:\n",
    "    return \"HHE\" if (binary and label.upper() in [\"HEM\",\"FNH\"]) else (\"HCC\" if label.upper()==\"HCC\" else label)\n",
    "\n",
    "all_items = list_videos(ROOT_DIR)\n",
    "print(\"T·ªïng:\", len(all_items))\n",
    "\n",
    "train_items, val_items, test_items = make_split(all_items, CFG[\"split_ratio\"], SEED)\n",
    "label_map = label_map_from_items(all_items, CFG[\"binary\"])\n",
    "inv_labels = [k for k,v in sorted(label_map.items(), key=lambda kv: kv[1])]\n",
    "print(\"Classes:\", inv_labels)\n",
    "print(\"Train/Val/Test:\", len(train_items), len(val_items), len(test_items))\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:36:41.907382Z",
     "start_time": "2025-10-03T09:36:41.886672Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:58.795085Z",
     "iopub.execute_input": "2025-10-03T10:01:58.795506Z",
     "iopub.status.idle": "2025-10-03T10:01:58.822208Z",
     "shell.execute_reply.started": "2025-10-03T10:01:58.795484Z",
     "shell.execute_reply": "2025-10-03T10:01:58.821582Z"
    },
    "id": "72f67596159c386b",
    "outputId": "172d37bb-9535-46db-823a-22fb048565a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "T·ªïng: 358\nClasses: ['HCC', 'HHE']\nTrain/Val/Test: 250 53 55\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "id": "e93f135bf70280e2",
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def uniform_indices(n_frames: int, T: int):\n",
    "    if n_frames <= 0:\n",
    "        return [0]*T\n",
    "    if n_frames >= T:\n",
    "        return [int(round(i*(n_frames-1)/(T-1))) for i in range(T)]\n",
    "    base = list(range(n_frames))\n",
    "    out = []\n",
    "    while len(out) < T:\n",
    "        out.extend(base)\n",
    "    return out[:T]\n",
    "\n",
    "def read_avi_as_rgb(path: str) -> np.ndarray:\n",
    "    \"\"\"ƒê·ªçc to√†n b·ªô khung h√¨nh d∆∞·ªõi d·∫°ng RGB uint8, shape (N,H,W,3).\"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    if not cap.isOpened():\n",
    "        return np.zeros((0,224,224,3), dtype=np.uint8)\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    if not frames:\n",
    "        return np.zeros((0,224,224,3), dtype=np.uint8)\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "def sample_preprocess_clip(path: str, T: int, img_size: int) -> np.ndarray:\n",
    "    vid = read_avi_as_rgb(path)  # (N,H,W,3)\n",
    "    N = vid.shape[0]\n",
    "    idxs = uniform_indices(N, T)\n",
    "    sel = vid[idxs] if N>0 else np.zeros((T, img_size, img_size, 3), dtype=np.uint8)\n",
    "    sel_resized = np.stack([cv2.resize(f, (img_size, img_size)) for f in sel], axis=0)\n",
    "    return sel_resized  # uint8\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:37:08.057181Z",
     "start_time": "2025-10-03T09:37:07.997185Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:58.823348Z",
     "iopub.execute_input": "2025-10-03T10:01:58.823739Z",
     "iopub.status.idle": "2025-10-03T10:01:58.831787Z",
     "shell.execute_reply.started": "2025-10-03T10:01:58.823722Z",
     "shell.execute_reply": "2025-10-03T10:01:58.830976Z"
    },
    "id": "e93f135bf70280e2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "7c131fb671f5885e",
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications import resnet50, efficientnet, mobilenet_v2\n",
    "\n",
    "def get_preprocess_fn(arch: str):\n",
    "    if arch == \"resnet50_lstm\":\n",
    "        return resnet50.preprocess_input\n",
    "    elif arch == \"efficientnet_b0_gru\":\n",
    "        return efficientnet.preprocess_input\n",
    "    elif arch == \"mobilenet_v2_gru\":\n",
    "        return mobilenet_v2.preprocess_input\n",
    "    elif arch == \"tiny_cnn_gru\":\n",
    "        # Simple normalization for custom CNN\n",
    "        return lambda x: (x / 255.0 - 0.5) * 2.0\n",
    "    else:\n",
    "        raise ValueError(\"Unknown arch\")\n",
    "\n",
    "def make_examples(items: List[Tuple[str,str]], binary: bool) -> List[Tuple[str,int]]:\n",
    "    ex = []\n",
    "    for path, cls in items:\n",
    "        ex.append((path, label_map[remap_label(cls, binary)]))\n",
    "    return ex\n",
    "\n",
    "def gen_examples(examples: List[Tuple[str,int]], T: int, img_size: int, arch: str):\n",
    "    preprocess_input = get_preprocess_fn(arch)\n",
    "    for path, y in examples:\n",
    "        x = sample_preprocess_clip(path, T, img_size)        # (T,H,W,3) uint8\n",
    "        x = preprocess_input(x.astype(np.float32))           # theo backbone\n",
    "        yield x, y\n",
    "\n",
    "def make_dataset(items, binary, T, img_size, arch, batch_size, shuffle=False, repeat=False, cache=False):\n",
    "    examples = make_examples(items, binary)\n",
    "    output_sig = (\n",
    "        tf.TensorSpec(shape=(T, img_size, img_size, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: gen_examples(examples, T, img_size, arch),\n",
    "        output_signature=output_sig\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(CFG[\"shuffle_buffer\"], seed=SEED, reshuffle_each_iteration=True)\n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    return ds, len(examples)\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:37:24.813633Z",
     "start_time": "2025-10-03T09:37:24.775421Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:58.832412Z",
     "iopub.execute_input": "2025-10-03T10:01:58.833138Z",
     "iopub.status.idle": "2025-10-03T10:01:58.853617Z",
     "shell.execute_reply.started": "2025-10-03T10:01:58.833119Z",
     "shell.execute_reply": "2025-10-03T10:01:58.85292Z"
    },
    "id": "7c131fb671f5885e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "14a50a98b5ee9e82",
   "cell_type": "markdown",
   "source": [
    "## ResNet50‚ÜíLSTM"
   ],
   "metadata": {
    "id": "14a50a98b5ee9e82"
   }
  },
  {
   "id": "efa402cbb33f9183",
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def build_resnet50_lstm(T, img_size, num_classes, freeze_backbone=True, rnn_units=256, bidir=False, dropout=0.3): # Reduced RNN units and disabled bidirectional\n",
    "    inp = tf.keras.layers.Input(shape=(T, img_size, img_size, 3))\n",
    "    base = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\", pooling='avg',\n",
    "                                          input_shape=(img_size, img_size, 3))\n",
    "    base.trainable = not freeze_backbone\n",
    "    x = layers.TimeDistributed(base)(inp)\n",
    "    # Add feature reduction to speed up RNN processing\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    if bidir:\n",
    "        x = layers.Bidirectional(layers.LSTM(rnn_units, dropout=dropout, return_sequences=False))(x)\n",
    "    else:\n",
    "        x = layers.LSTM(rnn_units, dropout=dropout, return_sequences=False)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inp, out, name=\"ResNet50_LSTM\")\n",
    "    return model, base"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:38:18.248628Z",
     "start_time": "2025-10-03T09:38:18.233066Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:58.985678Z",
     "iopub.execute_input": "2025-10-03T10:01:58.986241Z",
     "iopub.status.idle": "2025-10-03T10:01:58.992997Z",
     "shell.execute_reply.started": "2025-10-03T10:01:58.986219Z",
     "shell.execute_reply": "2025-10-03T10:01:58.992254Z"
    },
    "id": "efa402cbb33f9183"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "38da1840ce9dec30",
   "cell_type": "markdown",
   "source": [
    "## EfficientNetB0‚ÜíGRU"
   ],
   "metadata": {
    "id": "38da1840ce9dec30"
   }
  },
  {
   "id": "67e434a87fea617b",
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_efficientnet_b0_gru(T, img_size, num_classes, freeze_backbone=True, rnn_units=192, bidir=False, dropout=0.3): # Reduced units and disabled bidirectional\n",
    "    inp = tf.keras.layers.Input(shape=(T, img_size, img_size, 3))\n",
    "    base = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", pooling='avg',\n",
    "                                                input_shape=(img_size, img_size, 3))\n",
    "    base.trainable = not freeze_backbone\n",
    "    x = layers.TimeDistributed(base)(inp)        # (B,T,1280)\n",
    "    # Add feature reduction to speed up RNN processing\n",
    "    x = layers.Dense(384, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    if bidir:\n",
    "        x = layers.Bidirectional(layers.GRU(rnn_units, dropout=dropout, return_sequences=False))(x)\n",
    "    else:\n",
    "        x = layers.GRU(rnn_units, dropout=dropout, return_sequences=False)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inp, out, name=\"EffB0_GRU\")\n",
    "    return model, base\n",
    "\n",
    "# Add lightweight MobileNetV2 model for even faster training\n",
    "def build_mobilenet_v2_gru(T, img_size, num_classes, freeze_backbone=True, rnn_units=128, bidir=False, dropout=0.3):\n",
    "    inp = tf.keras.layers.Input(shape=(T, img_size, img_size, 3))\n",
    "    base = tf.keras.applications.MobileNetV2(include_top=False, weights=\"imagenet\", pooling='avg',\n",
    "                                            input_shape=(img_size, img_size, 3))\n",
    "    base.trainable = not freeze_backbone\n",
    "    x = layers.TimeDistributed(base)(inp)        # (B,T,1280)\n",
    "    # Feature reduction for faster processing\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    if bidir:\n",
    "        x = layers.Bidirectional(layers.GRU(rnn_units, dropout=dropout, return_sequences=False))(x)\n",
    "    else:\n",
    "        x = layers.GRU(rnn_units, dropout=dropout, return_sequences=False)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inp, out, name=\"MobileNetV2_GRU\")\n",
    "    return model, base\n",
    "\n",
    "# Add ultra-lightweight custom CNN model for maximum speed\n",
    "def build_tiny_cnn_gru(T, img_size, num_classes, freeze_backbone=True, rnn_units=64, bidir=False, dropout=0.2):\n",
    "    inp = tf.keras.layers.Input(shape=(T, img_size, img_size, 3))\n",
    "\n",
    "    # Ultra-lightweight CNN backbone instead of pretrained models\n",
    "    def tiny_cnn_block():\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "            layers.MaxPooling2D(2),\n",
    "            layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "            layers.MaxPooling2D(2),\n",
    "            layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "            layers.GlobalAveragePooling2D()\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    base = tiny_cnn_block()\n",
    "    x = layers.TimeDistributed(base)(inp)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.GRU(rnn_units, dropout=dropout, return_sequences=False)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inp, out, name=\"TinyCNN_GRU\")\n",
    "    return model, base"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:38:27.694807Z",
     "start_time": "2025-10-03T09:38:27.663659Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:58.994431Z",
     "iopub.execute_input": "2025-10-03T10:01:58.994654Z",
     "iopub.status.idle": "2025-10-03T10:01:59.015866Z",
     "shell.execute_reply.started": "2025-10-03T10:01:58.994638Z",
     "shell.execute_reply": "2025-10-03T10:01:59.015286Z"
    },
    "id": "67e434a87fea617b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "32c3807575387af3",
   "cell_type": "code",
   "source": [
    "def build_model(arch, T, img_size, num_classes, freeze_backbone=True):\n",
    "    if arch == \"resnet50_lstm\":\n",
    "        return build_resnet50_lstm(T, img_size, num_classes, freeze_backbone=freeze_backbone)\n",
    "    elif arch == \"efficientnet_b0_gru\":\n",
    "        return build_efficientnet_b0_gru(T, img_size, num_classes, freeze_backbone=freeze_backbone)\n",
    "    elif arch == \"mobilenet_v2_gru\":\n",
    "        return build_mobilenet_v2_gru(T, img_size, num_classes, freeze_backbone=freeze_backbone)\n",
    "    elif arch == \"tiny_cnn_gru\":\n",
    "        return build_tiny_cnn_gru(T, img_size, num_classes, freeze_backbone=freeze_backbone)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown arch\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:38:35.837731Z",
     "start_time": "2025-10-03T09:38:35.828795Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:59.016511Z",
     "iopub.execute_input": "2025-10-03T10:01:59.016679Z",
     "iopub.status.idle": "2025-10-03T10:01:59.034184Z",
     "shell.execute_reply.started": "2025-10-03T10:01:59.016665Z",
     "shell.execute_reply": "2025-10-03T10:01:59.033606Z"
    },
    "id": "32c3807575387af3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "16e3ac41eeaaebff",
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "\n",
    "def compute_class_weights(items, binary=False):\n",
    "    counts = {}\n",
    "    for _,c in items:\n",
    "        name = remap_label(c, binary)\n",
    "        counts[name] = counts.get(name, 0) + 1\n",
    "    total = sum(counts.values())\n",
    "    classes = [k for v,k in sorted(label_map.items(), key=lambda kv: kv[1])]\n",
    "    weights = {label_map[c]: total/(len(counts)*counts[c]) for c in classes}\n",
    "    return weights, counts\n",
    "\n",
    "class ConsoleMetrics(callbacks.Callback):\n",
    "    def __init__(self, val_ds, y_val_true, label_names):\n",
    "        super().__init__()\n",
    "        self.val_ds = val_ds\n",
    "        self.y_true = y_val_true\n",
    "        self.label_names = label_names\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_prob = self.model.predict(self.val_ds, verbose=0)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        acc = accuracy_score(self.y_true, y_pred)\n",
    "        p,r,f,_ = precision_recall_fscore_support(self.y_true, y_pred, average='weighted', zero_division=0)\n",
    "        print(f\"  >> [VAL] acc={acc:.4f} | f1={f:.4f}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:39:12.959638Z",
     "start_time": "2025-10-03T09:39:11.227591Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:59.034899Z",
     "iopub.execute_input": "2025-10-03T10:01:59.035115Z",
     "iopub.status.idle": "2025-10-03T10:01:59.053308Z",
     "shell.execute_reply.started": "2025-10-03T10:01:59.0351Z",
     "shell.execute_reply": "2025-10-03T10:01:59.052636Z"
    },
    "id": "16e3ac41eeaaebff"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "46d4c6cf4fd1bca3",
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "def train_and_evaluate(arch=\"efficientnet_b0_gru\", cfg=CFG, save_best=\"best_tf_A.h5\"):\n",
    "    train_ds, n_train = make_dataset(train_items, cfg[\"binary\"], cfg[\"frames\"], cfg[\"img_size\"], arch,\n",
    "                                     cfg[\"batch_size\"], shuffle=True, cache=cfg[\"cache_ds\"])\n",
    "    val_ds,   n_val   = make_dataset(val_items,   cfg[\"binary\"], cfg[\"frames\"], cfg[\"img_size\"], arch,\n",
    "                                     cfg[\"batch_size\"], shuffle=False, cache=cfg[\"cache_ds\"])\n",
    "    test_ds,  n_test  = make_dataset(test_items,  cfg[\"binary\"], cfg[\"frames\"], cfg[\"img_size\"], arch,\n",
    "                                     cfg[\"batch_size\"], shuffle=False, cache=False)\n",
    "\n",
    "    num_classes = len(inv_labels)\n",
    "\n",
    "    y_val_true = np.array([label_map[remap_label(c, cfg[\"binary\"])] for _,c in val_items])\n",
    "    y_test_true= np.array([label_map[remap_label(c, cfg[\"binary\"])] for _,c in test_items])\n",
    "\n",
    "    # Model (giai ƒëo·∫°n 1: freeze backbone)\n",
    "    model, base = build_model(arch, cfg[\"frames\"], cfg[\"img_size\"], num_classes, freeze_backbone=True)\n",
    "\n",
    "    # Optimizer AdamW n·∫øu c√≥ (TF 2.16 c√≥ s·∫µn), fallback Adam\n",
    "    try:\n",
    "        opt_head = optimizers.experimental.AdamW(learning_rate=cfg[\"lr_head\"], weight_decay=cfg[\"weight_decay\"])\n",
    "        opt_ft   = optimizers.experimental.AdamW(learning_rate=cfg[\"lr_ft\"],  weight_decay=cfg[\"weight_decay\"])\n",
    "    except:\n",
    "        opt_head = optimizers.Adam(learning_rate=cfg[\"lr_head\"])\n",
    "        opt_ft   = optimizers.Adam(learning_rate=cfg[\"lr_ft\"])\n",
    "\n",
    "    model.compile(optimizer=opt_head, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # class weights\n",
    "    class_weights = None\n",
    "    if not cfg[\"binary\"]:\n",
    "        cw, counts = compute_class_weights(all_items, binary=cfg[\"binary\"])\n",
    "        class_weights = cw\n",
    "        print(\"Class counts:\", counts)\n",
    "        print(\"Class weights:\", class_weights)\n",
    "\n",
    "    cb = [\n",
    "        callbacks.ModelCheckpoint(save_best, monitor=\"val_accuracy\", save_best_only=True, save_weights_only=False, verbose=1),\n",
    "    ]\n",
    "\n",
    "    print(f\"===> Phase 1: Train head (freeze backbone) | epochs={cfg['epochs_head']}\")\n",
    "    hist1 = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=cfg[\"epochs_head\"],\n",
    "        class_weight=class_weights,\n",
    "        verbose=1,\n",
    "        callbacks=cb\n",
    "    )\n",
    "\n",
    "    # Phase 2: unfreeze m·ªôt ph·∫ßn (ho·∫∑c to√†n b·ªô) backbone & fine-tune\n",
    "    base.trainable = True\n",
    "    model.compile(optimizer=opt_ft, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    print(f\"===> Phase 2: Fine-tune backbone | epochs={cfg['epochs_ft']}\")\n",
    "    hist2 = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=cfg[\"epochs_ft\"],\n",
    "        class_weight=class_weights,\n",
    "        verbose=1,\n",
    "        callbacks=cb\n",
    "    )\n",
    "\n",
    "    best_model = tf.keras.models.load_model(save_best)\n",
    "    t0 = time.time()\n",
    "    y_prob = best_model.predict(test_ds, verbose=0)\n",
    "    infer_time = (time.time() - t0)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_test_true, y_pred)\n",
    "    p,r,f,_ = precision_recall_fscore_support(y_test_true, y_pred, average='weighted', zero_division=0)\n",
    "    cm = confusion_matrix(y_test_true, y_pred)\n",
    "    report = classification_report(y_test_true, y_pred, target_names=inv_labels, digits=4, zero_division=0)\n",
    "\n",
    "    ms_per_vid = 1000.0 * infer_time / max(1, len(test_items))\n",
    "    print(f\"\\n===== TEST ({arch}) =====\")\n",
    "    print(f\"[TEST] acc={acc:.4f} | prec={p:.4f} | rec={r:.4f} | f1={f:.4f} | infer={ms_per_vid:.1f} ms/vid\")\n",
    "    print(\"Classification report:\\n\", report)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc, \"prec\": p, \"rec\": r, \"f1\": f, \"cm\": cm, \"ms_per_vid\": ms_per_vid,\n",
    "        \"labels\": inv_labels, \"best_path\": save_best\n",
    "    }"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:40:10.520971Z",
     "start_time": "2025-10-03T09:40:09.975427Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:59.055205Z",
     "iopub.execute_input": "2025-10-03T10:01:59.05544Z",
     "iopub.status.idle": "2025-10-03T10:01:59.070157Z",
     "shell.execute_reply.started": "2025-10-03T10:01:59.05542Z",
     "shell.execute_reply": "2025-10-03T10:01:59.069633Z"
    },
    "id": "46d4c6cf4fd1bca3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "90042df18268d9d6",
   "cell_type": "code",
   "source": [
    "CFG[\"binary\"] = True          # ƒë·ªïi False ƒë·ªÉ ch·∫°y 3-class\n",
    "CFG[\"frames\"] = 3\n",
    "CFG[\"img_size\"] = 48\n",
    "CFG[\"batch_size\"] = 4\n",
    "CFG[\"epochs_head\"] = 1\n",
    "CFG[\"epochs_ft\"] = 2\n",
    "\n",
    "res_A2 = train_and_evaluate(\n",
    "    arch=\"efficientnet_b0_gru\",\n",
    "    cfg=CFG,\n",
    "    save_best=\"best_A2_efficientnet_b0_gru.h5\"\n",
    ")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-03T10:01:59.070902Z",
     "iopub.execute_input": "2025-10-03T10:01:59.071101Z"
    },
    "id": "90042df18268d9d6",
    "outputId": "ccd8bac4-329a-4e27-9c61-1a1815a91342"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "===> Phase 1: Train head (freeze backbone) | epochs=3\nEpoch 1/3\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "E0000 00:00:1759485917.680845      36 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EffB0_GRU_1/time_distributed_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CFG_A1 = CFG.copy()\n",
    "CFG_A1[\"batch_size\"] = 2\n",
    "\n",
    "res_A1 = train_and_evaluate(\n",
    "    arch=\"resnet50_lstm\",\n",
    "    cfg=CFG_A1,\n",
    "    save_best=\"best_A1_resnet50_lstm.h5\"\n",
    ")"
   ],
   "id": "94ade85a5e8668fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# New lightweight configuration for fastest training\n",
    "CFG_FAST = CFG.copy()\n",
    "CFG_FAST[\"frames\"] = 6  # Even fewer frames\n",
    "CFG_FAST[\"img_size\"] = 96  # Smaller image size\n",
    "CFG_FAST[\"batch_size\"] = 6  # Larger batch size\n",
    "CFG_FAST[\"epochs_head\"] = 1  # Minimal head training\n",
    "CFG_FAST[\"epochs_ft\"] = 4  # Reduced fine-tuning\n",
    "\n",
    "res_A3 = train_and_evaluate(\n",
    "    arch=\"mobilenet_v2_gru\",\n",
    "    cfg=CFG_FAST,\n",
    "    save_best=\"best_A3_mobilenet_v2_gru.h5\"\n",
    ")"
   ],
   "id": "2395f5d402255d59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ultra-minimal configuration for absolute fastest training\n",
    "CFG_ULTRA_FAST = {\n",
    "    \"binary\": True,\n",
    "    \"split_ratio\": (0.7, 0.15, 0.15),\n",
    "    \"frames\": 3,  # C·ª±c k·ª≥ √≠t frames - ch·ªâ 3 frame\n",
    "    \"img_size\": 48,  # Si√™u nh·ªè - ch·ªâ 48x48 pixels\n",
    "    \"batch_size\": 12,  # Batch size l·ªõn nh·∫•t c√≥ th·ªÉ\n",
    "    \"epochs_head\": 1,  # Ch·ªâ 1 epoch\n",
    "    \"epochs_ft\": 2,  # Ch·ªâ 2 epochs fine-tuning\n",
    "    \"lr_head\": 3e-3,  # Learning rate cao ƒë·ªÉ h·ªôi t·ª• nhanh\n",
    "    \"lr_ft\": 8e-4,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"shuffle_buffer\": 8,  # Buffer c·ª±c nh·ªè\n",
    "    \"num_parallel_calls\": tf.data.AUTOTUNE,\n",
    "    \"cache_ds\": True,\n",
    "}\n",
    "\n",
    "print(\"üöÄ TRAINING SI√äU NHANH v·ªõi TinyCNN - C·∫•u h√¨nh t·ªëi gi·∫£n nh·∫•t!\")\n",
    "res_ULTRA = train_and_evaluate(\n",
    "    arch=\"tiny_cnn_gru\",\n",
    "    cfg=CFG_ULTRA_FAST,\n",
    "    save_best=\"best_ULTRA_tiny_cnn.h5\"\n",
    ")"
   ],
   "id": "129fe063a2f07b5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CH·ªà CH·∫†Y M·ªòT M√î H√åNH DUY NH·∫§T - NHANH NH·∫§T\n",
    "print(\"üöÄ CH·ªà CH·∫†Y TinyCNN - NHANH NH·∫§T V√Ä √çT MEMORY NH·∫§T!\")\n",
    "\n",
    "# C·∫•u h√¨nh t·ªëi gi·∫£n tuy·ªát ƒë·ªëi cho memory th·∫•p\n",
    "CFG_MINIMAL = {\n",
    "    \"binary\": True,\n",
    "    \"split_ratio\": (0.7, 0.15, 0.15),\n",
    "    \"frames\": 2,  # CH·ªà 2 frames - c·ª±c k·ª≥ √≠t\n",
    "    \"img_size\": 32,  # CH·ªà 32x32 pixels - si√™u nh·ªè\n",
    "    \"batch_size\": 2,  # Batch size nh·ªè nh·∫•t\n",
    "    \"epochs_head\": 1,  # CH·ªà 1 epoch\n",
    "    \"epochs_ft\": 1,   # CH·ªà 1 epoch fine-tuning\n",
    "    \"lr_head\": 5e-3,  # Learning rate cao\n",
    "    \"lr_ft\": 1e-3,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"shuffle_buffer\": 4,  # Buffer c·ª±c nh·ªè\n",
    "    \"num_parallel_calls\": 1,  # Ch·ªâ 1 thread\n",
    "    \"cache_ds\": False, # T·∫ÆT caching\n",
    "}\n",
    "\n",
    "res_MINIMAL = train_and_evaluate(\n",
    "    arch=\"tiny_cnn_gru\",\n",
    "    cfg=CFG_MINIMAL,\n",
    "    save_best=\"best_MINIMAL_tiny_cnn.h5\"\n",
    ")\n"
   ],
   "id": "6ccbfee9bdfe20ce"
  }
 ]
}
