{
 "cells": [
  {
   "cell_type": "code",
   "id": "b12af81d-5c34-40c7-bb5e-e59eb53aaa4d",
   "metadata": {
    "id": "b12af81d-5c34-40c7-bb5e-e59eb53aaa4d",
    "outputId": "487404aa-1e0c-47df-b28b-33f79d458042",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-22T05:07:04.632629Z"
    }
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Image Classification with E-ELAN Lite (PyTorch)\n",
    "- EELANLite block (group conv -> channel shuffle -> concat -> 1x1 fuse + residual)\n",
    "- CNN+Pooling backbone + EELANLite + GAP + Linear\n",
    "- ImageFolder dataloader (train/val; if val missing, auto-split with independent transforms)\n",
    "- Train/Validate with AMP (CUDA), cosine lr schedule\n",
    "- Save best checkpoint; Predict image/folder top-k\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    \"data_root\": \"E:\\Pycharm\\Advanced-Reading-on-Computer-Vision\\Images\\CNN_MultiClass_data\",          # change me\n",
    "    \"train_dir\": \"animals\",\n",
    "    \"val_dir\": \"val\",                # optional\n",
    "    \"auto_split_val_ratio\": 0.1,\n",
    "\n",
    "    \"img_size\": 224,\n",
    "    \"num_workers\": 4,\n",
    "\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 2e-3,\n",
    "    \"weight_decay\": 0.05,\n",
    "    \"label_smoothing\": 0.0,\n",
    "    \"amp\": True,   # CUDA-only\n",
    "\n",
    "    \"C_stem\": 32,\n",
    "    \"C_stage\": 96,\n",
    "    \"m\": 2.0,\n",
    "    \"g\": 2,\n",
    "\n",
    "    \"use_cosine\": True,\n",
    "    \"min_lr_scale\": 0.05,\n",
    "\n",
    "    \"out_dir\": \"runs/cls_eelan\",\n",
    "    \"best_ckpt\": \"best.pt\",\n",
    "    \"topk\": 5,\n",
    "\n",
    "    \"predict_path\": None,  # set path to image or folder if you want to predict after training\n",
    "    \"seed\": 42,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Utils\n",
    "# -------------------------------\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "class ConvBNAct(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k=3, s=1, p=None, g=1, act=True):\n",
    "        super().__init__()\n",
    "        if p is None:\n",
    "            p = (k - 1) // 2\n",
    "        self.conv = nn.Conv2d(c_in, c_out, k, s, p, groups=g, bias=False)\n",
    "        self.bn   = nn.BatchNorm2d(c_out)\n",
    "        self.act  = nn.SiLU(inplace=True) if act else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "def channel_shuffle(x: torch.Tensor, groups: int) -> torch.Tensor:\n",
    "    if groups <= 1:\n",
    "        return x\n",
    "    b, c, h, w = x.shape\n",
    "    assert c % groups == 0, \"channels must be divisible by groups\"\n",
    "    x = x.view(b, groups, c // groups, h, w)\n",
    "    x = x.transpose(1, 2).contiguous()\n",
    "    x = x.view(b, c, h, w)\n",
    "    return x\n",
    "\n",
    "class EELANLite(nn.Module):\n",
    "    \"\"\"\n",
    "    Minimal E-ELAN:\n",
    "      - 1x1 group conv expand to m*C (groups=g)\n",
    "      - 4 branches with depths [0,1,2,3] (3x3 group conv)\n",
    "      - channel shuffle per branch\n",
    "      - concat -> 1x1 fuse to C_out (default C_in), residual if shapes match\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 C_in: int,\n",
    "                 C_out: int = None,\n",
    "                 m: float = 2.0,\n",
    "                 g: int = 2,\n",
    "                 branch_depths: List[int] = None,\n",
    "                 use_skip: bool = True):\n",
    "        super().__init__()\n",
    "        assert m >= 1\n",
    "        self.C_in  = C_in\n",
    "        self.C_out = C_in if C_out is None else C_out\n",
    "        self.m     = m\n",
    "        self.g     = g\n",
    "        self.use_skip = use_skip and (self.C_out == self.C_in)\n",
    "\n",
    "        C_exp = int(round(self.m * self.C_in))\n",
    "        C_exp = max(4*self.g, (C_exp // (4*self.g)) * (4*self.g))  # divisible by 4*g\n",
    "        self.C_exp = C_exp\n",
    "\n",
    "        self.expand = ConvBNAct(self.C_in, self.C_exp, k=1, s=1, p=0, g=self.g, act=True)\n",
    "\n",
    "        self.num_branches = 4\n",
    "        self.split_ch = self.C_exp // self.num_branches\n",
    "        assert self.C_exp % self.num_branches == 0\n",
    "\n",
    "        if branch_depths is None:\n",
    "            branch_depths = [0, 1, 2, 3]\n",
    "        self.branch_depths = branch_depths[:self.num_branches]\n",
    "\n",
    "        branches = []\n",
    "        for d in self.branch_depths:\n",
    "            layers = []\n",
    "            in_ch  = self.split_ch\n",
    "            for _ in range(d):\n",
    "                layers.append(ConvBNAct(in_ch, in_ch, k=3, s=1, p=1, g=self.g, act=True))\n",
    "            branches.append(nn.Sequential(*layers) if layers else nn.Identity())\n",
    "        self.branches = nn.ModuleList(branches)\n",
    "\n",
    "        self.fuse = ConvBNAct(self.C_exp, self.C_out, k=1, s=1, p=0, g=1, act=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        y = self.expand(x)\n",
    "        chunks = torch.chunk(y, self.num_branches, dim=1)\n",
    "        outs = [br(ch) for br, ch in zip(self.branches, chunks)]\n",
    "        outs = [channel_shuffle(t, self.g) for t in outs]\n",
    "        y = torch.cat(outs, dim=1)\n",
    "        y = self.fuse(y)\n",
    "        if self.use_skip and y.shape == identity.shape:\n",
    "            y = y + identity\n",
    "        return y\n",
    "\n",
    "class EELANClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN+Pooling backbone with one EELANLite stage\n",
    "      Stem:  Conv 3x3 s=2 -> Conv 3x3\n",
    "      Stage1: MaxPool s=2 -> Conv 3x3\n",
    "      EELAN stage: EELANLite(C_stage)\n",
    "      Neck:  Conv 1x1\n",
    "      Head:  GAP -> Linear(num_classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int,\n",
    "                 C_in=3, C_stem=32, C_stage=96,\n",
    "                 m=2.0, g=2, neck_channels=128):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            ConvBNAct(C_in, C_stem, k=3, s=2),     # H/2\n",
    "            ConvBNAct(C_stem, C_stem, k=3, s=1),\n",
    "        )\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # H/4\n",
    "            ConvBNAct(C_stem, C_stage, k=3, s=1),\n",
    "        )\n",
    "        self.eelan = EELANLite(C_stage, C_stage, m=m, g=g, branch_depths=[0,1,2,3], use_skip=True)\n",
    "        self.neck = ConvBNAct(C_stage, neck_channels, k=1, s=1, p=0, g=1, act=True)\n",
    "        self.head = nn.Linear(neck_channels, num_classes)\n",
    "\n",
    "        # ---- FIX: init conv weights with 'relu' gain (PyTorch không hỗ trợ 'silu' ở calculate_gain) ----\n",
    "        for m_ in self.modules():\n",
    "            if isinstance(m_, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m_.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m_, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m_.weight, 1.0)\n",
    "                nn.init.constant_(m_.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.eelan(x)\n",
    "        x = self.neck(x)\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1).squeeze(-1).squeeze(-1)  # (B, C)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "# -------------------------------\n",
    "# Data\n",
    "# -------------------------------\n",
    "def build_transforms(img_size=224, is_train=True):\n",
    "    if is_train:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                 std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                 std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "\n",
    "def build_dataloaders(cfg):\n",
    "    train_root = os.path.join(cfg[\"data_root\"], cfg[\"train_dir\"])\n",
    "    val_root   = os.path.join(cfg[\"data_root\"], cfg[\"val_dir\"])\n",
    "\n",
    "    if os.path.isdir(val_root) and any(os.scandir(val_root)):\n",
    "        # explicit train/val\n",
    "        train_ds = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], True))\n",
    "        val_ds   = datasets.ImageFolder(val_root,   transform=build_transforms(cfg[\"img_size\"], False))\n",
    "    else:\n",
    "        # ---- FIX: auto-split with independent datasets (avoid shared transform pitfall) ----\n",
    "        base_train = datasets.ImageFolder(train_root)  # no transform\n",
    "        n_total = len(base_train)\n",
    "        n_val = max(1, int(round(n_total * float(cfg[\"auto_split_val_ratio\"]))))\n",
    "        n_train = n_total - n_val\n",
    "        # reproducible split\n",
    "        gen = torch.Generator().manual_seed(CFG[\"seed\"])\n",
    "        train_idx, val_idx = torch.utils.data.random_split(range(n_total), [n_train, n_val], generator=gen)\n",
    "\n",
    "        train_ds_full = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], True))\n",
    "        val_ds_full   = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], False))\n",
    "        train_ds = Subset(train_ds_full, train_idx.indices if hasattr(train_idx, \"indices\") else train_idx)\n",
    "        val_ds   = Subset(val_ds_full,   val_idx.indices   if hasattr(val_idx, \"indices\")   else val_idx)\n",
    "\n",
    "    # class names from the underlying dataset of train_ds\n",
    "    class_names = train_ds.dataset.classes if hasattr(train_ds, \"dataset\") else train_ds.classes\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg[\"batch_size\"], shuffle=True,\n",
    "                              num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=cfg[\"batch_size\"], shuffle=False,\n",
    "                              num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    return train_loader, val_loader, class_names\n",
    "\n",
    "# -------------------------------\n",
    "# Train / Eval\n",
    "# -------------------------------\n",
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    out = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        out.append((correct_k * (100.0 / batch_size)).item())\n",
    "    return out\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device, epoch, loss_fn):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    tot = 0\n",
    "    top1_sum = 0.0\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if scaler is not None:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float16):\n",
    "                logits = model(x)\n",
    "                loss = loss_fn(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bsz = x.size(0)\n",
    "        acc1 = accuracy_topk(logits.detach(), y, topk=(1,))[0]\n",
    "        running_loss += loss.item() * bsz\n",
    "        top1_sum += acc1 * bsz / 100.0\n",
    "        tot += bsz\n",
    "\n",
    "    return running_loss / tot, (top1_sum / tot) * 100.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    tot = 0\n",
    "    top1_sum = 0.0\n",
    "    per_class_correct = None\n",
    "    per_class_count = None\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        bsz = x.size(0)\n",
    "        acc1 = accuracy_topk(logits, y, topk=(1,))[0]\n",
    "        running_loss += loss.item() * bsz\n",
    "        top1_sum += acc1 * bsz / 100.0\n",
    "        tot += bsz\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        if per_class_correct is None:\n",
    "            ncls = int(logits.shape[1])\n",
    "            per_class_correct = torch.zeros(ncls, dtype=torch.long, device=device)\n",
    "            per_class_count   = torch.zeros(ncls, dtype=torch.long, device=device)\n",
    "        for t, p in zip(y, preds):\n",
    "            per_class_count[t] += 1\n",
    "            per_class_correct[t] += int(t == p)\n",
    "\n",
    "    avg_loss = running_loss / tot\n",
    "    top1 = (top1_sum / tot) * 100.0\n",
    "    if per_class_correct is not None:\n",
    "        per_class_acc = (per_class_correct.float() / per_class_count.clamp(min=1).float()) * 100.0\n",
    "        per_class_acc = per_class_acc.cpu().tolist()\n",
    "    else:\n",
    "        per_class_acc = None\n",
    "    return avg_loss, top1, per_class_acc\n",
    "\n",
    "# -------------------------------\n",
    "# Predict\n",
    "# -------------------------------\n",
    "@torch.no_grad()\n",
    "def predict_images(model, device, class_names, path, img_size=224, topk=5):\n",
    "    if os.path.isdir(path):\n",
    "        import glob\n",
    "        files = []\n",
    "        for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.webp\",\"*.JPG\",\"*.PNG\",\"*.JPEG\"):\n",
    "            files.extend(glob.glob(os.path.join(path, ext)))\n",
    "        files = sorted(files)\n",
    "    else:\n",
    "        files = [path]\n",
    "\n",
    "    tfm = build_transforms(img_size, is_train=False)\n",
    "    results = []\n",
    "    model.eval()\n",
    "    for f in files:\n",
    "        try:\n",
    "            im = Image.open(f).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] cannot open {f}: {e}\")\n",
    "            continue\n",
    "        x = tfm(im).unsqueeze(0).to(device)\n",
    "        logits = model(x)\n",
    "        prob = torch.softmax(logits, dim=1)[0]\n",
    "        topv, topi = prob.topk(min(topk, len(class_names)))\n",
    "        preds = [(class_names[i], float(topv[j].item())) for j, i in enumerate(topi)]\n",
    "        results.append((f, preds))\n",
    "    return results\n",
    "\n",
    "# -------------------------------\n",
    "# Main\n",
    "# -------------------------------\n",
    "def main(cfg):\n",
    "    set_seed(cfg[\"seed\"])\n",
    "    os.makedirs(cfg[\"out_dir\"], exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    print(\"Building dataloaders...\")\n",
    "    train_loader, val_loader, class_names = build_dataloaders(cfg)\n",
    "    num_classes = len(class_names)\n",
    "    print(f\"Classes ({num_classes}): {class_names}\")\n",
    "\n",
    "    print(\"Building model...\")\n",
    "    model = EELANClassifier(\n",
    "        num_classes=num_classes,\n",
    "        C_in=3,\n",
    "        C_stem=cfg[\"C_stem\"],\n",
    "        C_stage=cfg[\"C_stage\"],\n",
    "        m=cfg[\"m\"],\n",
    "        g=cfg[\"g\"],\n",
    "        neck_channels=128,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "    if cfg[\"use_cosine\"]:\n",
    "        # epoch-wise cosine schedule\n",
    "        def lr_lambda(ep):\n",
    "            if cfg[\"epochs\"] <= 1:\n",
    "                return 1.0\n",
    "            t = ep / (cfg[\"epochs\"] - 1)\n",
    "            cos = 0.5 * (1 + math.cos(math.pi * t))\n",
    "            return cfg[\"min_lr_scale\"] + (1 - cfg[\"min_lr_scale\"]) * cos\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=cfg[\"label_smoothing\"]) if cfg[\"label_smoothing\"] > 0 \\\n",
    "              else nn.CrossEntropyLoss()\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if (cfg[\"amp\"] and device.type == \"cuda\") else None\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        t0 = time.time()\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scaler, device, epoch, loss_fn)\n",
    "        val_loss, val_acc, per_class_acc = evaluate(model, val_loader, device, loss_fn)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save({\n",
    "                \"model\": best_wts,\n",
    "                \"classes\": class_names,\n",
    "                \"cfg\": cfg\n",
    "            }, os.path.join(cfg[\"out_dir\"], cfg[\"best_ckpt\"]))\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d}/{cfg['epochs']:03d} | \"\n",
    "              f\"train_loss {train_loss:.4f} acc@1 {train_acc:.2f}% | \"\n",
    "              f\"val_loss {val_loss:.4f} acc@1 {val_acc:.2f}% | \"\n",
    "              f\"time {dt:.1f}s\")\n",
    "\n",
    "        if per_class_acc is not None:\n",
    "            show = \", \".join([f\"{cls}:{acc:.1f}%\" for cls, acc in zip(class_names, per_class_acc)])\n",
    "            print(f\"  per-class acc: {show}\")\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    print(f\"Best val acc@1: {best_acc:.2f}%  | checkpoint: {os.path.join(cfg['out_dir'], cfg['best_ckpt'])}\")\n",
    "\n",
    "    if cfg[\"predict_path\"]:\n",
    "        print(f\"Predicting: {cfg['predict_path']}\")\n",
    "        results = predict_images(model, device, class_names, cfg[\"predict_path\"],\n",
    "                                 img_size=cfg[\"img_size\"], topk=cfg[\"topk\"])\n",
    "        for f, preds in results:\n",
    "            print(f\"\\n{f}\")\n",
    "            for cls, p in preds:\n",
    "                print(f\"  {cls:>20s}: {p:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(CFG)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataloaders...\n",
      "Classes (3): ['cats', 'dogs', 'panda']\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\buian\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/020 | train_loss 0.8768 acc@1 55.30% | val_loss 0.8188 acc@1 59.33% | time 109.7s\n",
      "  per-class acc: cats:62.2%, dogs:27.5%, panda:91.1%\n",
      "Epoch 002/020 | train_loss 0.8114 acc@1 59.93% | val_loss 0.8586 acc@1 57.00% | time 105.0s\n",
      "  per-class acc: cats:46.7%, dogs:64.2%, panda:58.4%\n",
      "Epoch 003/020 | train_loss 0.8013 acc@1 58.70% | val_loss 1.0621 acc@1 44.00% | time 104.4s\n",
      "  per-class acc: cats:35.6%, dogs:79.8%, panda:12.9%\n",
      "Epoch 004/020 | train_loss 0.7311 acc@1 62.81% | val_loss 1.1882 acc@1 41.33% | time 108.2s\n",
      "  per-class acc: cats:92.2%, dogs:25.7%, panda:12.9%\n",
      "Epoch 005/020 | train_loss 0.6955 acc@1 64.26% | val_loss 0.7073 acc@1 64.67% | time 102.4s\n",
      "  per-class acc: cats:65.6%, dogs:40.4%, panda:90.1%\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
