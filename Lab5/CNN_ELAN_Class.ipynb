{
 "cells": [
  {
   "cell_type": "code",
   "id": "b12af81d-5c34-40c7-bb5e-e59eb53aaa4d",
   "metadata": {
    "id": "b12af81d-5c34-40c7-bb5e-e59eb53aaa4d",
    "outputId": "487404aa-1e0c-47df-b28b-33f79d458042",
    "ExecuteTime": {
     "end_time": "2025-10-22T06:14:15.557612Z",
     "start_time": "2025-10-22T06:13:29.586428Z"
    }
   },
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Image Classification with E-ELAN Lite (PyTorch)\n",
    "- EELANLite block (group conv -> channel shuffle -> concat -> 1x1 fuse + residual)\n",
    "- CNN+Pooling backbone + EELANLite + GAP + Linear\n",
    "- ImageFolder dataloader (train/val; if val missing, auto-split with independent transforms)\n",
    "- Train/Validate with AMP (CUDA), cosine lr schedule\n",
    "- Save best checkpoint; Predict image/folder top-k\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    \"data_root\": \"E:\\Pycharm\\Advanced-Reading-on-Computer-Vision\\Images\\CNN_MultiClass_data\",  # change me\n",
    "    \"train_dir\": \"animals\",\n",
    "    \"val_dir\": \"val\",  # optional\n",
    "    \"auto_split_val_ratio\": 0.1,\n",
    "\n",
    "    \"img_size\": 224,\n",
    "    \"num_workers\": 4,\n",
    "\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 2e-3,\n",
    "    \"weight_decay\": 0.05,\n",
    "    \"label_smoothing\": 0.0,\n",
    "    \"amp\": True,  # CUDA-only\n",
    "\n",
    "    \"C_stem\": 32,\n",
    "    \"C_stage\": 96,\n",
    "    \"m\": 2.0,\n",
    "    \"g\": 2,\n",
    "\n",
    "    \"use_cosine\": True,\n",
    "    \"min_lr_scale\": 0.05,\n",
    "\n",
    "    \"out_dir\": \"runs/cls_eelan\",\n",
    "    \"best_ckpt\": \"best.pt\",\n",
    "    \"topk\": 5,\n",
    "\n",
    "    \"predict_path\": None,  # set path to image or folder if you want to predict after training\n",
    "    \"seed\": 42,\n",
    "\n",
    "    \"resume_ckpt\": \"runs/cls_eelan/last.pt\",\n",
    "    \"infer_ckpt\": \"runs/cls_eelan/best.pt\",\n",
    "    \"save_last\": \"last.pt\",\n",
    "    \"save_optimizer_state\": True,\n",
    "    \"preds_csv\": \"preds.csv\",\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Utils\n",
    "# -------------------------------\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "class ConvBNAct(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k=3, s=1, p=None, g=1, act=True):\n",
    "        super().__init__()\n",
    "        if p is None:\n",
    "            p = (k - 1) // 2\n",
    "        self.conv = nn.Conv2d(c_in, c_out, k, s, p, groups=g, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.SiLU(inplace=True) if act else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "def channel_shuffle(x: torch.Tensor, groups: int) -> torch.Tensor:\n",
    "    if groups <= 1:\n",
    "        return x\n",
    "    b, c, h, w = x.shape\n",
    "    assert c % groups == 0, \"channels must be divisible by groups\"\n",
    "    x = x.view(b, groups, c // groups, h, w)\n",
    "    x = x.transpose(1, 2).contiguous()\n",
    "    x = x.view(b, c, h, w)\n",
    "    return x\n",
    "\n",
    "\n",
    "class EELANLite(nn.Module):\n",
    "    \"\"\"\n",
    "    Minimal E-ELAN:\n",
    "      - 1x1 group conv expand to m*C (groups=g)\n",
    "      - 4 branches with depths [0,1,2,3] (3x3 group conv)\n",
    "      - channel shuffle per branch\n",
    "      - concat -> 1x1 fuse to C_out (default C_in), residual if shapes match\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 C_in: int,\n",
    "                 C_out: int = None,\n",
    "                 m: float = 2.0,\n",
    "                 g: int = 2,\n",
    "                 branch_depths: List[int] = None,\n",
    "                 use_skip: bool = True):\n",
    "        super().__init__()\n",
    "        assert m >= 1\n",
    "        self.C_in = C_in\n",
    "        self.C_out = C_in if C_out is None else C_out\n",
    "        self.m = m\n",
    "        self.g = g\n",
    "        self.use_skip = use_skip and (self.C_out == self.C_in)\n",
    "\n",
    "        C_exp = int(round(self.m * self.C_in))\n",
    "        C_exp = max(4 * self.g, (C_exp // (4 * self.g)) * (4 * self.g))  # divisible by 4*g\n",
    "        self.C_exp = C_exp\n",
    "\n",
    "        self.expand = ConvBNAct(self.C_in, self.C_exp, k=1, s=1, p=0, g=self.g, act=True)\n",
    "\n",
    "        self.num_branches = 4\n",
    "        self.split_ch = self.C_exp // self.num_branches\n",
    "        assert self.C_exp % self.num_branches == 0\n",
    "\n",
    "        if branch_depths is None:\n",
    "            branch_depths = [0, 1, 2, 3]\n",
    "        self.branch_depths = branch_depths[:self.num_branches]\n",
    "\n",
    "        branches = []\n",
    "        for d in self.branch_depths:\n",
    "            layers = []\n",
    "            in_ch = self.split_ch\n",
    "            for _ in range(d):\n",
    "                layers.append(ConvBNAct(in_ch, in_ch, k=3, s=1, p=1, g=self.g, act=True))\n",
    "            branches.append(nn.Sequential(*layers) if layers else nn.Identity())\n",
    "        self.branches = nn.ModuleList(branches)\n",
    "\n",
    "        self.fuse = ConvBNAct(self.C_exp, self.C_out, k=1, s=1, p=0, g=1, act=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        y = self.expand(x)\n",
    "        chunks = torch.chunk(y, self.num_branches, dim=1)\n",
    "        outs = [br(ch) for br, ch in zip(self.branches, chunks)]\n",
    "        outs = [channel_shuffle(t, self.g) for t in outs]\n",
    "        y = torch.cat(outs, dim=1)\n",
    "        y = self.fuse(y)\n",
    "        if self.use_skip and y.shape == identity.shape:\n",
    "            y = y + identity\n",
    "        return y\n",
    "\n",
    "\n",
    "class EELANClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN+Pooling backbone with one EELANLite stage\n",
    "      Stem:  Conv 3x3 s=2 -> Conv 3x3\n",
    "      Stage1: MaxPool s=2 -> Conv 3x3\n",
    "      EELAN stage: EELANLite(C_stage)\n",
    "      Neck:  Conv 1x1\n",
    "      Head:  GAP -> Linear(num_classes)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int,\n",
    "                 C_in=3, C_stem=32, C_stage=96,\n",
    "                 m=2.0, g=2, neck_channels=128):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            ConvBNAct(C_in, C_stem, k=3, s=2),  # H/2\n",
    "            ConvBNAct(C_stem, C_stem, k=3, s=1),\n",
    "        )\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # H/4\n",
    "            ConvBNAct(C_stem, C_stage, k=3, s=1),\n",
    "        )\n",
    "        self.eelan = EELANLite(C_stage, C_stage, m=m, g=g, branch_depths=[0, 1, 2, 3], use_skip=True)\n",
    "        self.neck = ConvBNAct(C_stage, neck_channels, k=1, s=1, p=0, g=1, act=True)\n",
    "        self.head = nn.Linear(neck_channels, num_classes)\n",
    "\n",
    "        # ---- FIX: init conv weights with 'relu' gain (PyTorch không hỗ trợ 'silu' ở calculate_gain) ----\n",
    "        for m_ in self.modules():\n",
    "            if isinstance(m_, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m_.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m_, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m_.weight, 1.0)\n",
    "                nn.init.constant_(m_.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.eelan(x)\n",
    "        x = self.neck(x)\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1).squeeze(-1).squeeze(-1)  # (B, C)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Data\n",
    "# -------------------------------\n",
    "def build_transforms(img_size=224, is_train=True):\n",
    "    if is_train:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "\n",
    "def build_dataloaders(cfg):\n",
    "    train_root = os.path.join(cfg[\"data_root\"], cfg[\"train_dir\"])\n",
    "    val_root = os.path.join(cfg[\"data_root\"], cfg[\"val_dir\"])\n",
    "\n",
    "    if os.path.isdir(val_root) and any(os.scandir(val_root)):\n",
    "        # explicit train/val\n",
    "        train_ds = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], True))\n",
    "        val_ds = datasets.ImageFolder(val_root, transform=build_transforms(cfg[\"img_size\"], False))\n",
    "    else:\n",
    "        # ---- FIX: auto-split with independent datasets (avoid shared transform pitfall) ----\n",
    "        base_train = datasets.ImageFolder(train_root)  # no transform\n",
    "        n_total = len(base_train)\n",
    "        n_val = max(1, int(round(n_total * float(cfg[\"auto_split_val_ratio\"]))))\n",
    "        n_train = n_total - n_val\n",
    "        # reproducible split\n",
    "        gen = torch.Generator().manual_seed(CFG[\"seed\"])\n",
    "        train_idx, val_idx = torch.utils.data.random_split(range(n_total), [n_train, n_val], generator=gen)\n",
    "\n",
    "        train_ds_full = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], True))\n",
    "        val_ds_full = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], False))\n",
    "        train_ds = Subset(train_ds_full, train_idx.indices if hasattr(train_idx, \"indices\") else train_idx)\n",
    "        val_ds = Subset(val_ds_full, val_idx.indices if hasattr(val_idx, \"indices\") else val_idx)\n",
    "\n",
    "    # class names from the underlying dataset of train_ds\n",
    "    class_names = train_ds.dataset.classes if hasattr(train_ds, \"dataset\") else train_ds.classes\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg[\"batch_size\"], shuffle=True,\n",
    "                              num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg[\"batch_size\"], shuffle=False,\n",
    "                            num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    return train_loader, val_loader, class_names\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Checkpoint Utils\n",
    "# -------------------------------\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, best_acc, class_names, cfg, filepath):\n",
    "    \"\"\"Save complete checkpoint including model, optimizer state, and metadata\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'best_acc': best_acc,\n",
    "        'class_names': class_names,\n",
    "        'cfg': cfg,\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved: {filepath}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(model, filepath, device, load_optimizer=False, optimizer=None, scheduler=None):\n",
    "    \"\"\"Load checkpoint and return metadata\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {filepath}\")\n",
    "\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    metadata = {\n",
    "        'epoch': checkpoint.get('epoch', 0),\n",
    "        'best_acc': checkpoint.get('best_acc', 0.0),\n",
    "        'class_names': checkpoint.get('class_names', []),\n",
    "        'cfg': checkpoint.get('cfg', {}),\n",
    "        'timestamp': checkpoint.get('timestamp', 'Unknown')\n",
    "    }\n",
    "\n",
    "    if load_optimizer and optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if scheduler is not None and checkpoint.get('scheduler_state_dict'):\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    print(f\"Checkpoint loaded: {filepath}\")\n",
    "    print(f\"  - Epoch: {metadata['epoch']}\")\n",
    "    print(f\"  - Best Accuracy: {metadata['best_acc']:.2f}%\")\n",
    "    print(f\"  - Classes: {metadata['class_names']}\")\n",
    "    print(f\"  - Saved at: {metadata['timestamp']}\")\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def write_preds_csv(results, out_csv):\n",
    "    \"\"\"\n",
    "    results: List[(filepath, [(cls_name, prob_float), ...])]\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        # header: file, top1_cls, top1_prob, topk_json\n",
    "        w.writerow([\"file\", \"top1_cls\", \"top1_prob\", \"topk_json\"])\n",
    "        for fpath, preds in results:\n",
    "            if len(preds) > 0:\n",
    "                top1_cls, top1_prob = preds[0][0], float(preds[0][1])\n",
    "            else:\n",
    "                top1_cls, top1_prob = \"\", 0.0\n",
    "            # lưu cả top-k dưới dạng json\n",
    "            topk_json = json.dumps([{\"cls\": c, \"prob\": float(p)} for c, p in preds], ensure_ascii=False)\n",
    "            w.writerow([fpath, top1_cls, f\"{top1_prob:.6f}\", topk_json])\n",
    "    print(f\"[info] wrote prediction CSV to: {out_csv}\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Train / Eval\n",
    "# -------------------------------\n",
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    out = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        out.append((correct_k * (100.0 / batch_size)).item())\n",
    "    return out\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device, epoch, loss_fn):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    tot = 0\n",
    "    top1_sum = 0.0\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if scaler is not None:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float16):\n",
    "                logits = model(x)\n",
    "                loss = loss_fn(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bsz = x.size(0)\n",
    "        acc1 = accuracy_topk(logits.detach(), y, topk=(1,))[0]\n",
    "        running_loss += loss.item() * bsz\n",
    "        top1_sum += acc1 * bsz / 100.0\n",
    "        tot += bsz\n",
    "\n",
    "    return running_loss / tot, (top1_sum / tot) * 100.0\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    tot = 0\n",
    "    top1_sum = 0.0\n",
    "    per_class_correct = None\n",
    "    per_class_count = None\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        bsz = x.size(0)\n",
    "        acc1 = accuracy_topk(logits, y, topk=(1,))[0]\n",
    "        running_loss += loss.item() * bsz\n",
    "        top1_sum += acc1 * bsz / 100.0\n",
    "        tot += bsz\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        if per_class_correct is None:\n",
    "            ncls = int(logits.shape[1])\n",
    "            per_class_correct = torch.zeros(ncls, dtype=torch.long, device=device)\n",
    "            per_class_count = torch.zeros(ncls, dtype=torch.long, device=device)\n",
    "        for t, p in zip(y, preds):\n",
    "            per_class_count[t] += 1\n",
    "            per_class_correct[t] += int(t == p)\n",
    "\n",
    "    avg_loss = running_loss / tot\n",
    "    top1 = (top1_sum / tot) * 100.0\n",
    "    if per_class_correct is not None:\n",
    "        per_class_acc = (per_class_correct.float() / per_class_count.clamp(min=1).float()) * 100.0\n",
    "        per_class_acc = per_class_acc.cpu().tolist()\n",
    "    else:\n",
    "        per_class_acc = None\n",
    "    return avg_loss, top1, per_class_acc\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Predict\n",
    "# -------------------------------\n",
    "@torch.no_grad()\n",
    "def predict_images(model, device, class_names, path, img_size=224, topk=5):\n",
    "    if os.path.isdir(path):\n",
    "        import glob\n",
    "        files = []\n",
    "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.webp\", \"*.JPG\", \"*.PNG\", \"*.JPEG\"):\n",
    "            files.extend(glob.glob(os.path.join(path, ext)))\n",
    "        files = sorted(files)\n",
    "    else:\n",
    "        files = [path]\n",
    "\n",
    "    tfm = build_transforms(img_size, is_train=False)\n",
    "    results = []\n",
    "    model.eval()\n",
    "    for f in files:\n",
    "        try:\n",
    "            im = Image.open(f).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] cannot open {f}: {e}\")\n",
    "            continue\n",
    "        x = tfm(im).unsqueeze(0).to(device)\n",
    "        logits = model(x)\n",
    "        prob = torch.softmax(logits, dim=1)[0]\n",
    "        topv, topi = prob.topk(min(topk, len(class_names)))\n",
    "        preds = [(class_names[i], float(topv[j].item())) for j, i in enumerate(topi)]\n",
    "        results.append((f, preds))\n",
    "    return results\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Main\n",
    "# -------------------------------\n",
    "def main(cfg):\n",
    "    set_seed(cfg[\"seed\"])\n",
    "    os.makedirs(cfg[\"out_dir\"], exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    print(\"Building dataloaders...\")\n",
    "    train_loader, val_loader, class_names = build_dataloaders(cfg)\n",
    "    num_classes = len(class_names)\n",
    "    print(f\"Classes ({num_classes}): {class_names}\")\n",
    "\n",
    "    print(\"Building model...\")\n",
    "    model = EELANClassifier(\n",
    "        num_classes=num_classes,\n",
    "        C_in=3,\n",
    "        C_stem=cfg[\"C_stem\"],\n",
    "        C_stage=cfg[\"C_stage\"],\n",
    "        m=cfg[\"m\"],\n",
    "        g=cfg[\"g\"],\n",
    "        neck_channels=128,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "    if cfg[\"use_cosine\"]:\n",
    "        # epoch-wise cosine schedule\n",
    "        def lr_lambda(ep):\n",
    "            if cfg[\"epochs\"] <= 1:\n",
    "                return 1.0\n",
    "            t = ep / (cfg[\"epochs\"] - 1)\n",
    "            cos = 0.5 * (1 + math.cos(math.pi * t))\n",
    "            return cfg[\"min_lr_scale\"] + (1 - cfg[\"min_lr_scale\"]) * cos\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    # ----- Inference-only mode -----\n",
    "    if cfg.get(\"infer_ckpt\") and cfg.get(\"predict_path\"):\n",
    "        ckpt_path = cfg[\"infer_ckpt\"]\n",
    "        if os.path.isfile(ckpt_path):\n",
    "            print(f\"[infer-only] Loading checkpoint: {ckpt_path}\")\n",
    "            meta = load_checkpoint(model, ckpt_path, device=device)\n",
    "            class_names_ckpt = meta.get(\"class_names\", class_names)\n",
    "            if class_names_ckpt and class_names_ckpt != class_names:\n",
    "                print(\"[warn] classes in ckpt differ from current dataset. Using checkpoint classes from ckpt.\")\n",
    "                class_names = class_names_ckpt\n",
    "            results = predict_images(model, device, class_names, cfg[\"predict_path\"],\n",
    "                                     img_size=cfg[\"img_size\"], topk=cfg[\"topk\"])\n",
    "            for f, preds in results:\n",
    "                print(f\"\\n{f}\")\n",
    "                for cls, p in preds:\n",
    "                    print(f\"  {cls:>20s}: {p:.4f}\")\n",
    "            out_csv = os.path.join(cfg[\"out_dir\"], cfg[\"preds_csv\"])\n",
    "            write_preds_csv(results, out_csv)\n",
    "            return\n",
    "        else:\n",
    "            print(f\"[error] infer_ckpt not found: {ckpt_path}\")\n",
    "            return\n",
    "\n",
    "    # ----- Resume from checkpoint (optional) -----\n",
    "    if cfg.get(\"resume_ckpt\"):\n",
    "        ckpt_path = cfg[\"resume_ckpt\"]\n",
    "        if os.path.isfile(ckpt_path):\n",
    "            print(f\"[resume] Loading checkpoint: {ckpt_path}\")\n",
    "            _classes_meta = load_checkpoint(\n",
    "                model,\n",
    "                filepath=ckpt_path,\n",
    "                device=device,\n",
    "                load_optimizer=True,  # nếu muốn load lại optimizer/scheduler\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler\n",
    "            )\n",
    "\n",
    "            # đồng bộ lại thông tin class nếu khác\n",
    "            if _classes_meta is not None:\n",
    "                ckpt_classes = _classes_meta.get(\"class_names\", None)\n",
    "                if ckpt_classes and ckpt_classes != class_names:\n",
    "                    print(\"[warn] classes in ckpt differ from current dataset. Using dataset classes.\")\n",
    "        else:\n",
    "            print(f\"[warn] resume_ckpt not found: {ckpt_path}\")\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=cfg[\"label_smoothing\"]) if cfg[\"label_smoothing\"] > 0 \\\n",
    "        else nn.CrossEntropyLoss()\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if (cfg[\"amp\"] and device.type == \"cuda\") else None\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        t0 = time.time()\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scaler, device, epoch, loss_fn)\n",
    "        val_loss, val_acc, per_class_acc = evaluate(model, val_loader, device, loss_fn)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # save best (đã có)\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_wts = copy.deepcopy(model.state_dict())\n",
    "            save_checkpoint(\n",
    "                model, optimizer, scheduler,\n",
    "                epoch=epoch, best_acc=best_acc,\n",
    "                class_names=class_names, cfg=cfg,\n",
    "                filepath=os.path.join(cfg[\"out_dir\"], cfg[\"best_ckpt\"])\n",
    "            )\n",
    "\n",
    "        # luôn lưu last.pt sau mỗi epoch (để resume)\n",
    "        save_checkpoint(\n",
    "            model, optimizer, scheduler,\n",
    "            epoch=epoch, best_acc=best_acc,\n",
    "            class_names=class_names, cfg=cfg,\n",
    "            filepath=os.path.join(cfg[\"out_dir\"], cfg[\"save_last\"])\n",
    "        )\n",
    "\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        print(f\"Epoch {epoch + 1:03d}/{cfg['epochs']:03d} | \"\n",
    "              f\"train_loss {train_loss:.4f} acc@1 {train_acc:.2f}% | \"\n",
    "              f\"val_loss {val_loss:.4f} acc@1 {val_acc:.2f}% | \"\n",
    "              f\"time {dt:.1f}s\")\n",
    "\n",
    "        if per_class_acc is not None:\n",
    "            show = \", \".join([f\"{cls}:{acc:.1f}%\" for cls, acc in zip(class_names, per_class_acc)])\n",
    "            print(f\"  per-class acc: {show}\")\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    print(f\"Best val acc@1: {best_acc:.2f}%  | checkpoint: {os.path.join(cfg['out_dir'], cfg['best_ckpt'])}\")\n",
    "\n",
    "    # ----- Run prediction after training if predict_path is set -----\n",
    "    if cfg[\"predict_path\"]:\n",
    "        print(f\"Predicting: {cfg['predict_path']}\")\n",
    "        results = predict_images(model, device, class_names, cfg[\"predict_path\"],\n",
    "                                 img_size=cfg[\"img_size\"], topk=cfg[\"topk\"])\n",
    "        for f, preds in results:\n",
    "            print(f\"\\n{f}\")\n",
    "            for cls, p in preds:\n",
    "                print(f\"  {cls:>20s}: {p:.4f}\")\n",
    "        # ghi csv\n",
    "        out_csv = os.path.join(cfg[\"out_dir\"], cfg[\"preds_csv\"])\n",
    "        write_preds_csv(results, out_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(CFG)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataloaders...\n",
      "Classes (3): ['cats', 'dogs', 'panda']\n",
      "Building model...\n",
      "[warn] resume_ckpt not found: runs/cls_eelan/last.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 606\u001B[0m\n\u001B[0;32m    602\u001B[0m         write_preds_csv(results, out_csv)\n\u001B[0;32m    605\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 606\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCFG\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[6], line 552\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(cfg)\u001B[0m\n\u001B[0;32m    550\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(cfg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m]):\n\u001B[0;32m    551\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 552\u001B[0m     train_loss, train_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    553\u001B[0m     val_loss, val_acc, per_class_acc \u001B[38;5;241m=\u001B[39m evaluate(model, val_loader, device, loss_fn)\n\u001B[0;32m    555\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m scheduler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "Cell \u001B[1;32mIn[6], line 373\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, loader, optimizer, scaler, device, epoch, loss_fn)\u001B[0m\n\u001B[0;32m    371\u001B[0m     logits \u001B[38;5;241m=\u001B[39m model(x)\n\u001B[0;32m    372\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(logits, y)\n\u001B[1;32m--> 373\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    374\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    376\u001B[0m bsz \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\_tensor.py:647\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    638\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    639\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    640\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    645\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    646\u001B[0m     )\n\u001B[1;32m--> 647\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    349\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    351\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 354\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    362\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\autograd\\graph.py:829\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    827\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 829\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    830\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    831\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    833\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
