{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Image Classification with E-ELAN Lite (PyTorch)\n",
    "- EELANLite block (group conv -> channel shuffle -> concat -> 1x1 fuse + residual)\n",
    "- CNN+Pooling backbone + EELANLite + GAP + Linear\n",
    "- ImageFolder dataloader (train/val; if val missing, auto-split with independent transforms)\n",
    "- Train/Validate with AMP (CUDA), cosine lr schedule\n",
    "- Save best checkpoint; Predict image/folder top-k\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    \"data_root\": \"E:\\Pycharm\\Advanced-Reading-on-Computer-Vision\\Images\\CNN_MultiClass_data\",  # change me\n",
    "    \"train_dir\": \"animals\",\n",
    "    \"val_dir\": \"val\",  # optional\n",
    "    \"auto_split_val_ratio\": 0.1,\n",
    "\n",
    "    \"img_size\": 224,\n",
    "    \"num_workers\": 4,\n",
    "\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 2e-3,\n",
    "    \"weight_decay\": 0.05,\n",
    "    \"label_smoothing\": 0.0,\n",
    "    \"amp\": True,  # CUDA-only\n",
    "\n",
    "    \"C_stem\": 32,\n",
    "    \"C_stage\": 96,\n",
    "    \"m\": 2.0,\n",
    "    \"g\": 2,\n",
    "\n",
    "    \"use_cosine\": True,\n",
    "    \"min_lr_scale\": 0.05,\n",
    "\n",
    "    \"out_dir\": \"runs/cls_eelan\",\n",
    "    \"best_ckpt\": \"best.pt\",\n",
    "    \"topk\": 5,\n",
    "\n",
    "    \"predict_path\": None,  # set path to image or folder if you want to predict after training\n",
    "    \"seed\": 42,\n",
    "\n",
    "    \"resume_ckpt\": \"runs/cls_eelan/last.pt\",\n",
    "    \"infer_ckpt\": \"runs/cls_eelan/best.pt\",\n",
    "    \"save_last\": \"last.pt\",\n",
    "    \"save_optimizer_state\": True,\n",
    "    \"preds_csv\": \"preds.csv\",\n",
    "\n",
    "}"
   ],
   "id": "6ed6c3effb45a8ac"
  },
  {
   "cell_type": "code",
   "id": "b12af81d-5c34-40c7-bb5e-e59eb53aaa4d",
   "metadata": {
    "id": "b12af81d-5c34-40c7-bb5e-e59eb53aaa4d",
    "outputId": "487404aa-1e0c-47df-b28b-33f79d458042",
    "ExecuteTime": {
     "end_time": "2025-10-22T08:11:49.345031Z",
     "start_time": "2025-10-22T07:41:04.949593Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Utils\n",
    "# -------------------------------\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "class ConvBNAct(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k=3, s=1, p=None, g=1, act=True):\n",
    "        super().__init__()\n",
    "        if p is None:\n",
    "            p = (k - 1) // 2\n",
    "        self.conv = nn.Conv2d(c_in, c_out, k, s, p, groups=g, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.SiLU(inplace=True) if act else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "def channel_shuffle(x: torch.Tensor, groups: int) -> torch.Tensor:\n",
    "    if groups <= 1:\n",
    "        return x\n",
    "    b, c, h, w = x.shape\n",
    "    assert c % groups == 0, \"channels must be divisible by groups\"\n",
    "    x = x.view(b, groups, c // groups, h, w)\n",
    "    x = x.transpose(1, 2).contiguous()\n",
    "    x = x.view(b, c, h, w)\n",
    "    return x\n",
    "\n",
    "\n",
    "class EELANLite(nn.Module):\n",
    "    \"\"\"\n",
    "    Minimal E-ELAN:\n",
    "      - 1x1 group conv expand to m*C (groups=g)\n",
    "      - 4 branches with depths [0,1,2,3] (3x3 group conv)\n",
    "      - channel shuffle per branch\n",
    "      - concat -> 1x1 fuse to C_out (default C_in), residual if shapes match\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 C_in: int,\n",
    "                 C_out: int = None,\n",
    "                 m: float = 2.0,\n",
    "                 g: int = 2,\n",
    "                 branch_depths: List[int] = None,\n",
    "                 use_skip: bool = True):\n",
    "        super().__init__()\n",
    "        assert m >= 1\n",
    "        self.C_in = C_in\n",
    "        self.C_out = C_in if C_out is None else C_out\n",
    "        self.m = m\n",
    "        self.g = g\n",
    "        self.use_skip = use_skip and (self.C_out == self.C_in)\n",
    "\n",
    "        C_exp = int(round(self.m * self.C_in))\n",
    "        C_exp = max(4 * self.g, (C_exp // (4 * self.g)) * (4 * self.g))  # divisible by 4*g\n",
    "        self.C_exp = C_exp\n",
    "\n",
    "        self.expand = ConvBNAct(self.C_in, self.C_exp, k=1, s=1, p=0, g=self.g, act=True)\n",
    "\n",
    "        self.num_branches = 4\n",
    "        self.split_ch = self.C_exp // self.num_branches\n",
    "        assert self.C_exp % self.num_branches == 0\n",
    "\n",
    "        if branch_depths is None:\n",
    "            branch_depths = [0, 1, 2, 3]\n",
    "        self.branch_depths = branch_depths[:self.num_branches]\n",
    "\n",
    "        branches = []\n",
    "        for d in self.branch_depths:\n",
    "            layers = []\n",
    "            in_ch = self.split_ch\n",
    "            for _ in range(d):\n",
    "                layers.append(ConvBNAct(in_ch, in_ch, k=3, s=1, p=1, g=self.g, act=True))\n",
    "            branches.append(nn.Sequential(*layers) if layers else nn.Identity())\n",
    "        self.branches = nn.ModuleList(branches)\n",
    "\n",
    "        self.fuse = ConvBNAct(self.C_exp, self.C_out, k=1, s=1, p=0, g=1, act=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        y = self.expand(x)\n",
    "        chunks = torch.chunk(y, self.num_branches, dim=1)\n",
    "        outs = [br(ch) for br, ch in zip(self.branches, chunks)]\n",
    "        outs = [channel_shuffle(t, self.g) for t in outs]\n",
    "        y = torch.cat(outs, dim=1)\n",
    "        y = self.fuse(y)\n",
    "        if self.use_skip and y.shape == identity.shape:\n",
    "            y = y + identity\n",
    "        return y\n",
    "\n",
    "\n",
    "class EELANClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN+Pooling backbone with one EELANLite stage\n",
    "      Stem:  Conv 3x3 s=2 -> Conv 3x3\n",
    "      Stage1: MaxPool s=2 -> Conv 3x3\n",
    "      EELAN stage: EELANLite(C_stage)\n",
    "      Neck:  Conv 1x1\n",
    "      Head:  GAP -> Linear(num_classes)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int,\n",
    "                 C_in=3, C_stem=32, C_stage=96,\n",
    "                 m=2.0, g=2, neck_channels=128):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            ConvBNAct(C_in, C_stem, k=3, s=2),  # H/2\n",
    "            ConvBNAct(C_stem, C_stem, k=3, s=1),\n",
    "        )\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # H/4\n",
    "            ConvBNAct(C_stem, C_stage, k=3, s=1),\n",
    "        )\n",
    "        self.eelan = EELANLite(C_stage, C_stage, m=m, g=g, branch_depths=[0, 1, 2, 3], use_skip=True)\n",
    "        self.neck = ConvBNAct(C_stage, neck_channels, k=1, s=1, p=0, g=1, act=True)\n",
    "        self.head = nn.Linear(neck_channels, num_classes)\n",
    "\n",
    "        # ---- FIX: init conv weights with 'relu' gain (PyTorch không hỗ trợ 'silu' ở calculate_gain) ----\n",
    "        for m_ in self.modules():\n",
    "            if isinstance(m_, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m_.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m_, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m_.weight, 1.0)\n",
    "                nn.init.constant_(m_.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.eelan(x)\n",
    "        x = self.neck(x)\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1).squeeze(-1).squeeze(-1)  # (B, C)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Data\n",
    "# -------------------------------\n",
    "def build_transforms(img_size=224, is_train=True):\n",
    "    if is_train:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "\n",
    "def build_dataloaders(cfg):\n",
    "    train_root = os.path.join(cfg[\"data_root\"], cfg[\"train_dir\"])\n",
    "    val_root = os.path.join(cfg[\"data_root\"], cfg[\"val_dir\"])\n",
    "\n",
    "    if os.path.isdir(val_root) and any(os.scandir(val_root)):\n",
    "        # explicit train/val\n",
    "        train_ds = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], True))\n",
    "        val_ds = datasets.ImageFolder(val_root, transform=build_transforms(cfg[\"img_size\"], False))\n",
    "    else:\n",
    "        # ---- FIX: auto-split with independent datasets (avoid shared transform pitfall) ----\n",
    "        base_train = datasets.ImageFolder(train_root)  # no transform\n",
    "        n_total = len(base_train)\n",
    "        n_val = max(1, int(round(n_total * float(cfg[\"auto_split_val_ratio\"]))))\n",
    "        n_train = n_total - n_val\n",
    "        # reproducible split\n",
    "        gen = torch.Generator().manual_seed(CFG[\"seed\"])\n",
    "        train_idx, val_idx = torch.utils.data.random_split(range(n_total), [n_train, n_val], generator=gen)\n",
    "\n",
    "        train_ds_full = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], True))\n",
    "        val_ds_full = datasets.ImageFolder(train_root, transform=build_transforms(cfg[\"img_size\"], False))\n",
    "        train_ds = Subset(train_ds_full, train_idx.indices if hasattr(train_idx, \"indices\") else train_idx)\n",
    "        val_ds = Subset(val_ds_full, val_idx.indices if hasattr(val_idx, \"indices\") else val_idx)\n",
    "\n",
    "    # class names from the underlying dataset of train_ds\n",
    "    class_names = train_ds.dataset.classes if hasattr(train_ds, \"dataset\") else train_ds.classes\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg[\"batch_size\"], shuffle=True,\n",
    "                              num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg[\"batch_size\"], shuffle=False,\n",
    "                            num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    return train_loader, val_loader, class_names\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Checkpoint Utils\n",
    "# -------------------------------\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, best_acc, class_names, cfg, filepath):\n",
    "    \"\"\"Save complete checkpoint including model, optimizer state, and metadata\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'best_acc': best_acc,\n",
    "        'class_names': class_names,\n",
    "        'cfg': cfg,\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved: {filepath}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(model, filepath, device, load_optimizer=False, optimizer=None, scheduler=None):\n",
    "    \"\"\"Load checkpoint and return metadata\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {filepath}\")\n",
    "\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    metadata = {\n",
    "        'epoch': checkpoint.get('epoch', 0),\n",
    "        'best_acc': checkpoint.get('best_acc', 0.0),\n",
    "        'class_names': checkpoint.get('class_names', []),\n",
    "        'cfg': checkpoint.get('cfg', {}),\n",
    "        'timestamp': checkpoint.get('timestamp', 'Unknown')\n",
    "    }\n",
    "\n",
    "    if load_optimizer and optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if scheduler is not None and checkpoint.get('scheduler_state_dict'):\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    print(f\"Checkpoint loaded: {filepath}\")\n",
    "    print(f\"  - Epoch: {metadata['epoch']}\")\n",
    "    print(f\"  - Best Accuracy: {metadata['best_acc']:.2f}%\")\n",
    "    print(f\"  - Classes: {metadata['class_names']}\")\n",
    "    print(f\"  - Saved at: {metadata['timestamp']}\")\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def write_preds_csv(results, out_csv):\n",
    "    \"\"\"\n",
    "    results: List[(filepath, [(cls_name, prob_float), ...])]\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        # header: file, top1_cls, top1_prob, topk_json\n",
    "        w.writerow([\"file\", \"top1_cls\", \"top1_prob\", \"topk_json\"])\n",
    "        for fpath, preds in results:\n",
    "            if len(preds) > 0:\n",
    "                top1_cls, top1_prob = preds[0][0], float(preds[0][1])\n",
    "            else:\n",
    "                top1_cls, top1_prob = \"\", 0.0\n",
    "            # lưu cả top-k dưới dạng json\n",
    "            topk_json = json.dumps([{\"cls\": c, \"prob\": float(p)} for c, p in preds], ensure_ascii=False)\n",
    "            w.writerow([fpath, top1_cls, f\"{top1_prob:.6f}\", topk_json])\n",
    "    print(f\"[info] wrote prediction CSV to: {out_csv}\")\n",
    "\n",
    "\n",
    "def ensure_dir(p):\n",
    "    if p and not os.path.exists(p):\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_history_csv(history, out_dir):\n",
    "    ensure_dir(out_dir)\n",
    "    df = pd.DataFrame(history)\n",
    "    csv_path = os.path.join(out_dir, \"history.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"[info] saved training history to: {csv_path}\")\n",
    "    return csv_path\n",
    "\n",
    "\n",
    "def plot_curves_from_history_csv(csv_path, out_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Loss\n",
    "    plt.figure()\n",
    "    plt.plot(df[\"epoch\"], df[\"train_loss\"], label=\"train_loss\")\n",
    "    plt.plot(df[\"epoch\"], df[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.xlabel(\"epoch\");\n",
    "    plt.ylabel(\"loss\");\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend();\n",
    "    plt.grid(True)\n",
    "    loss_png = os.path.join(out_dir, \"loss.png\")\n",
    "    plt.savefig(loss_png, bbox_inches=\"tight\");\n",
    "    plt.close()\n",
    "    print(f\"[info] saved: {loss_png}\")\n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(df[\"epoch\"], df[\"train_acc\"], label=\"train_acc\")\n",
    "    plt.plot(df[\"epoch\"], df[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.xlabel(\"epoch\");\n",
    "    plt.ylabel(\"accuracy (%)\");\n",
    "    plt.title(\"Accuracy@1\")\n",
    "    plt.legend();\n",
    "    plt.grid(True)\n",
    "    acc_png = os.path.join(out_dir, \"acc.png\")\n",
    "    plt.savefig(acc_png, bbox_inches=\"tight\");\n",
    "    plt.close()\n",
    "    print(f\"[info] saved: {acc_png}\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_precision_recall(model, loader, device, class_names, out_dir):\n",
    "    \"\"\"Chạy inference trên loader có nhãn → in Precision/Recall (macro/micro & per-class) + vẽ Confusion Matrix.\"\"\"\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y.cpu().numpy().tolist())\n",
    "\n",
    "    # Metrics\n",
    "    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    p_micro, r_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "    per_cls = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    report_txt = os.path.join(out_dir, \"pr_report.txt\")\n",
    "    ensure_dir(out_dir)\n",
    "    with open(report_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"== Precision/Recall Report ==\\n\")\n",
    "        f.write(f\"Macro  P={p_macro:.4f}  R={r_macro:.4f}  F1={f1_macro:.4f}\\n\")\n",
    "        f.write(f\"Micro  P={p_micro:.4f}  R={r_micro:.4f}  F1={f1_micro:.4f}\\n\\n\")\n",
    "        f.write(\"Per-class (P, R, F1):\\n\")\n",
    "        for i, cls in enumerate(class_names):\n",
    "            f.write(f\"- {cls:>20s}: P={per_cls[0][i]:.4f}  R={per_cls[1][i]:.4f}  F1={per_cls[2][i]:.4f}\\n\")\n",
    "        f.write(\"\\nFull classification report:\\n\")\n",
    "        f.write(classification_report(y_true, y_pred, target_names=class_names, digits=4, zero_division=0))\n",
    "    print(f\"[info] saved PR report: {report_txt}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
    "    plt.figure(figsize=(0.8 * len(class_names) + 3, 0.8 * len(class_names) + 3))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion Matrix');\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    # numbers\n",
    "    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label');\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    cm_png = os.path.join(out_dir, \"confusion_matrix.png\")\n",
    "    plt.savefig(cm_png, bbox_inches=\"tight\");\n",
    "    plt.close()\n",
    "    print(f\"[info] saved: {cm_png}\")\n",
    "\n",
    "    return {\n",
    "        \"macro\": {\"P\": p_macro, \"R\": r_macro, \"F1\": f1_macro},\n",
    "        \"micro\": {\"P\": p_micro, \"R\": r_micro, \"F1\": f1_micro},\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Train / Eval\n",
    "# -------------------------------\n",
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    out = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        out.append((correct_k * (100.0 / batch_size)).item())\n",
    "    return out\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device, epoch, loss_fn):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    tot = 0\n",
    "    top1_sum = 0.0\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if scaler is not None:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float16):\n",
    "                logits = model(x)\n",
    "                loss = loss_fn(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bsz = x.size(0)\n",
    "        acc1 = accuracy_topk(logits.detach(), y, topk=(1,))[0]\n",
    "        running_loss += loss.item() * bsz\n",
    "        top1_sum += acc1 * bsz / 100.0\n",
    "        tot += bsz\n",
    "\n",
    "    return running_loss / tot, (top1_sum / tot) * 100.0\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    tot = 0\n",
    "    top1_sum = 0.0\n",
    "    per_class_correct = None\n",
    "    per_class_count = None\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        bsz = x.size(0)\n",
    "        acc1 = accuracy_topk(logits, y, topk=(1,))[0]\n",
    "        running_loss += loss.item() * bsz\n",
    "        top1_sum += acc1 * bsz / 100.0\n",
    "        tot += bsz\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        if per_class_correct is None:\n",
    "            ncls = int(logits.shape[1])\n",
    "            per_class_correct = torch.zeros(ncls, dtype=torch.long, device=device)\n",
    "            per_class_count = torch.zeros(ncls, dtype=torch.long, device=device)\n",
    "        for t, p in zip(y, preds):\n",
    "            per_class_count[t] += 1\n",
    "            per_class_correct[t] += int(t == p)\n",
    "\n",
    "    avg_loss = running_loss / tot\n",
    "    top1 = (top1_sum / tot) * 100.0\n",
    "    if per_class_correct is not None:\n",
    "        per_class_acc = (per_class_correct.float() / per_class_count.clamp(min=1).float()) * 100.0\n",
    "        per_class_acc = per_class_acc.cpu().tolist()\n",
    "    else:\n",
    "        per_class_acc = None\n",
    "    return avg_loss, top1, per_class_acc\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Predict\n",
    "# -------------------------------\n",
    "@torch.no_grad()\n",
    "def predict_images(model, device, class_names, path, img_size=224, topk=5):\n",
    "    if os.path.isdir(path):\n",
    "        import glob\n",
    "        files = []\n",
    "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.webp\", \"*.JPG\", \"*.PNG\", \"*.JPEG\"):\n",
    "            files.extend(glob.glob(os.path.join(path, ext)))\n",
    "        files = sorted(files)\n",
    "    else:\n",
    "        files = [path]\n",
    "\n",
    "    tfm = build_transforms(img_size, is_train=False)\n",
    "    results = []\n",
    "    model.eval()\n",
    "    for f in files:\n",
    "        try:\n",
    "            im = Image.open(f).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] cannot open {f}: {e}\")\n",
    "            continue\n",
    "        x = tfm(im).unsqueeze(0).to(device)\n",
    "        logits = model(x)\n",
    "        prob = torch.softmax(logits, dim=1)[0]\n",
    "        topv, topi = prob.topk(min(topk, len(class_names)))\n",
    "        preds = [(class_names[i], float(topv[j].item())) for j, i in enumerate(topi)]\n",
    "        results.append((f, preds))\n",
    "    return results\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Main\n",
    "# -------------------------------\n",
    "def main(cfg):\n",
    "    set_seed(cfg[\"seed\"])\n",
    "    os.makedirs(cfg[\"out_dir\"], exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    print(\"Building dataloaders...\")\n",
    "    train_loader, val_loader, class_names = build_dataloaders(cfg)\n",
    "    num_classes = len(class_names)\n",
    "    print(f\"Classes ({num_classes}): {class_names}\")\n",
    "\n",
    "    print(\"Building model...\")\n",
    "    model = EELANClassifier(\n",
    "        num_classes=num_classes,\n",
    "        C_in=3,\n",
    "        C_stem=cfg[\"C_stem\"],\n",
    "        C_stage=cfg[\"C_stage\"],\n",
    "        m=cfg[\"m\"],\n",
    "        g=cfg[\"g\"],\n",
    "        neck_channels=128,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "    if cfg[\"use_cosine\"]:\n",
    "        # epoch-wise cosine schedule\n",
    "        def lr_lambda(ep):\n",
    "            if cfg[\"epochs\"] <= 1:\n",
    "                return 1.0\n",
    "            t = ep / (cfg[\"epochs\"] - 1)\n",
    "            cos = 0.5 * (1 + math.cos(math.pi * t))\n",
    "            return cfg[\"min_lr_scale\"] + (1 - cfg[\"min_lr_scale\"]) * cos\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    # ----- Inference-only mode -----\n",
    "    if cfg.get(\"infer_ckpt\") and cfg.get(\"predict_path\"):\n",
    "        ckpt_path = cfg[\"infer_ckpt\"]\n",
    "        if os.path.isfile(ckpt_path):\n",
    "            print(f\"[infer-only] Loading checkpoint: {ckpt_path}\")\n",
    "            meta = load_checkpoint(model, ckpt_path, device=device)\n",
    "            class_names_ckpt = meta.get(\"class_names\", class_names)\n",
    "            if class_names_ckpt and class_names_ckpt != class_names:\n",
    "                print(\"[warn] classes in ckpt differ from current dataset. Using checkpoint classes from ckpt.\")\n",
    "                class_names = class_names_ckpt\n",
    "            results = predict_images(model, device, class_names, cfg[\"predict_path\"],\n",
    "                                     img_size=cfg[\"img_size\"], topk=cfg[\"topk\"])\n",
    "            for f, preds in results:\n",
    "                print(f\"\\n{f}\")\n",
    "                for cls, p in preds:\n",
    "                    print(f\"  {cls:>20s}: {p:.4f}\")\n",
    "            out_csv = os.path.join(cfg[\"out_dir\"], cfg[\"preds_csv\"])\n",
    "            write_preds_csv(results, out_csv)\n",
    "            return\n",
    "        else:\n",
    "            print(f\"[error] infer_ckpt not found: {ckpt_path}\")\n",
    "            return\n",
    "\n",
    "    # ----- Resume from checkpoint (optional) -----\n",
    "    if cfg.get(\"resume_ckpt\"):\n",
    "        ckpt_path = cfg[\"resume_ckpt\"]\n",
    "        if os.path.isfile(ckpt_path):\n",
    "            print(f\"[resume] Loading checkpoint: {ckpt_path}\")\n",
    "            _classes_meta = load_checkpoint(\n",
    "                model,\n",
    "                filepath=ckpt_path,\n",
    "                device=device,\n",
    "                load_optimizer=True,  # nếu muốn load lại optimizer/scheduler\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler\n",
    "            )\n",
    "\n",
    "            # đồng bộ lại thông tin class nếu khác\n",
    "            if _classes_meta is not None:\n",
    "                ckpt_classes = _classes_meta.get(\"class_names\", None)\n",
    "                if ckpt_classes and ckpt_classes != class_names:\n",
    "                    print(\"[warn] classes in ckpt differ from current dataset. Using dataset classes.\")\n",
    "        else:\n",
    "            print(f\"[warn] resume_ckpt not found: {ckpt_path}\")\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=cfg[\"label_smoothing\"]) if cfg[\"label_smoothing\"] > 0 \\\n",
    "        else nn.CrossEntropyLoss()\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if (cfg[\"amp\"] and device.type == \"cuda\") else None\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        t0 = time.time()\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scaler, device, epoch, loss_fn)\n",
    "        val_loss, val_acc, per_class_acc = evaluate(model, val_loader, device, loss_fn)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # save best (đã có)\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_wts = copy.deepcopy(model.state_dict())\n",
    "            save_checkpoint(\n",
    "                model, optimizer, scheduler,\n",
    "                epoch=epoch, best_acc=best_acc,\n",
    "                class_names=class_names, cfg=cfg,\n",
    "                filepath=os.path.join(cfg[\"out_dir\"], cfg[\"best_ckpt\"])\n",
    "            )\n",
    "\n",
    "        # luôn lưu last.pt sau mỗi epoch (để resume)\n",
    "        save_checkpoint(\n",
    "            model, optimizer, scheduler,\n",
    "            epoch=epoch, best_acc=best_acc,\n",
    "            class_names=class_names, cfg=cfg,\n",
    "            filepath=os.path.join(cfg[\"out_dir\"], cfg[\"save_last\"])\n",
    "        )\n",
    "\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        print(f\"Epoch {epoch + 1:03d}/{cfg['epochs']:03d} | \"\n",
    "              f\"train_loss {train_loss:.4f} acc@1 {train_acc:.2f}% | \"\n",
    "              f\"val_loss {val_loss:.4f} acc@1 {val_acc:.2f}% | \"\n",
    "              f\"time {dt:.1f}s\")\n",
    "\n",
    "        if per_class_acc is not None:\n",
    "            show = \", \".join([f\"{cls}:{acc:.1f}%\" for cls, acc in zip(class_names, per_class_acc)])\n",
    "            print(f\"  per-class acc: {show}\")\n",
    "\n",
    "        history[\"epoch\"].append(epoch + 1)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    # Lưu lịch sử & vẽ đồ thị\n",
    "    hist_csv = save_history_csv(history, cfg[\"out_dir\"])\n",
    "    plot_curves_from_history_csv(hist_csv, cfg[\"out_dir\"])\n",
    "\n",
    "    # Precision/Recall + Confusion Matrix trên tập val (có nhãn)\n",
    "    _ = evaluate_precision_recall(model, val_loader, device, class_names, cfg[\"out_dir\"])\n",
    "\n",
    "    print(f\"Best val acc@1: {best_acc:.2f}%  | checkpoint: {os.path.join(cfg['out_dir'], cfg['best_ckpt'])}\")\n",
    "\n",
    "    # ----- Run prediction after training if predict_path is set -----\n",
    "    if cfg[\"predict_path\"]:\n",
    "        print(f\"Predicting: {cfg['predict_path']}\")\n",
    "        results = predict_images(model, device, class_names, cfg[\"predict_path\"],\n",
    "                                 img_size=cfg[\"img_size\"], topk=cfg[\"topk\"])\n",
    "        for f, preds in results:\n",
    "            print(f\"\\n{f}\")\n",
    "            for cls, p in preds:\n",
    "                print(f\"  {cls:>20s}: {p:.4f}\")\n",
    "        # ghi csv\n",
    "        out_csv = os.path.join(cfg[\"out_dir\"], cfg[\"preds_csv\"])\n",
    "        write_preds_csv(results, out_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(CFG)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataloaders...\n",
      "Classes (3): ['cats', 'dogs', 'panda']\n",
      "Building model...\n",
      "[resume] Loading checkpoint: runs/cls_eelan/last.pt\n",
      "Checkpoint loaded: runs/cls_eelan/last.pt\n",
      "  - Epoch: 19\n",
      "  - Best Accuracy: 79.33%\n",
      "  - Classes: ['cats', 'dogs', 'panda']\n",
      "  - Saved at: 2025-10-22 13:48:13\n",
      "Checkpoint saved: runs/cls_eelan\\best.pt\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 001/020 | train_loss 0.4132 acc@1 81.93% | val_loss 0.4623 acc@1 80.00% | time 90.8s\n",
      "  per-class acc: cats:85.6%, dogs:63.3%, panda:93.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 002/020 | train_loss 0.4133 acc@1 80.67% | val_loss 0.4452 acc@1 77.00% | time 88.8s\n",
      "  per-class acc: cats:65.6%, dogs:71.6%, panda:93.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 003/020 | train_loss 0.4295 acc@1 80.07% | val_loss 0.4815 acc@1 78.00% | time 89.9s\n",
      "  per-class acc: cats:86.7%, dogs:57.8%, panda:92.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 004/020 | train_loss 0.4199 acc@1 80.30% | val_loss 0.4502 acc@1 77.67% | time 88.4s\n",
      "  per-class acc: cats:85.6%, dogs:56.0%, panda:94.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 005/020 | train_loss 0.4243 acc@1 80.56% | val_loss 0.4637 acc@1 77.67% | time 88.3s\n",
      "  per-class acc: cats:78.9%, dogs:62.4%, panda:93.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 006/020 | train_loss 0.4349 acc@1 79.67% | val_loss 0.4623 acc@1 77.67% | time 89.2s\n",
      "  per-class acc: cats:86.7%, dogs:56.0%, panda:93.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 007/020 | train_loss 0.4429 acc@1 79.56% | val_loss 0.5396 acc@1 77.33% | time 87.9s\n",
      "  per-class acc: cats:82.2%, dogs:63.3%, panda:88.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 008/020 | train_loss 0.4412 acc@1 79.41% | val_loss 0.4567 acc@1 78.33% | time 88.6s\n",
      "  per-class acc: cats:70.0%, dogs:71.6%, panda:93.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 009/020 | train_loss 0.4562 acc@1 78.96% | val_loss 0.5506 acc@1 73.00% | time 88.6s\n",
      "  per-class acc: cats:77.8%, dogs:57.8%, panda:85.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 010/020 | train_loss 0.4627 acc@1 78.11% | val_loss 1.4356 acc@1 63.67% | time 88.3s\n",
      "  per-class acc: cats:57.8%, dogs:36.7%, panda:98.0%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 011/020 | train_loss 0.4484 acc@1 77.70% | val_loss 0.5991 acc@1 72.00% | time 97.9s\n",
      "  per-class acc: cats:97.8%, dogs:35.8%, panda:88.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 012/020 | train_loss 0.4309 acc@1 78.85% | val_loss 0.6413 acc@1 71.67% | time 99.4s\n",
      "  per-class acc: cats:84.4%, dogs:49.5%, panda:84.2%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 013/020 | train_loss 0.4574 acc@1 79.81% | val_loss 0.5506 acc@1 74.00% | time 98.4s\n",
      "  per-class acc: cats:94.4%, dogs:44.0%, panda:88.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 014/020 | train_loss 0.4384 acc@1 79.70% | val_loss 0.4739 acc@1 78.33% | time 95.0s\n",
      "  per-class acc: cats:78.9%, dogs:65.1%, panda:92.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 015/020 | train_loss 0.4460 acc@1 78.89% | val_loss 0.5303 acc@1 74.00% | time 95.9s\n",
      "  per-class acc: cats:92.2%, dogs:45.0%, panda:89.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 016/020 | train_loss 0.4496 acc@1 78.63% | val_loss 0.5567 acc@1 73.33% | time 94.3s\n",
      "  per-class acc: cats:58.9%, dogs:74.3%, panda:85.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 017/020 | train_loss 0.4500 acc@1 79.59% | val_loss 0.5871 acc@1 74.67% | time 93.6s\n",
      "  per-class acc: cats:60.0%, dogs:78.0%, panda:84.2%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 018/020 | train_loss 0.4443 acc@1 79.00% | val_loss 0.5276 acc@1 73.33% | time 93.4s\n",
      "  per-class acc: cats:87.8%, dogs:46.8%, panda:89.1%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 019/020 | train_loss 0.4340 acc@1 79.81% | val_loss 0.9832 acc@1 64.33% | time 93.7s\n",
      "  per-class acc: cats:71.1%, dogs:67.0%, panda:55.4%\n",
      "Checkpoint saved: runs/cls_eelan\\last.pt\n",
      "Epoch 020/020 | train_loss 0.4248 acc@1 80.07% | val_loss 0.6014 acc@1 75.00% | time 93.5s\n",
      "  per-class acc: cats:82.2%, dogs:60.6%, panda:84.2%\n",
      "Best val acc@1: 80.00%  | checkpoint: runs/cls_eelan\\best.pt\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
